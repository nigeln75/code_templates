{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook produces the Sankey diagrams in the paper. To get it set up, see [README](README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "from sankeyview import *\n",
    "from sankeyview.jupyter import show_sankey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset and set up hierarchies and partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'fruit_flows.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0abf960acfff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fruit_flows.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fruit_processes.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/nigelnicholson/anaconda3/lib/python3.6/site-packages/sankeyview/dataset.py\u001b[0m in \u001b[0;36mfrom_csv\u001b[0;34m(cls, flows_filename, dim_process_filename, dim_material_filename, dim_time_filename)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mflows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflows_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0mdim_process\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_process_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mdim_material\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_material_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nigelnicholson/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    644\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nigelnicholson/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nigelnicholson/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nigelnicholson/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nigelnicholson/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1388\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:4184)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:8449)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'fruit_flows.csv' does not exist"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.from_csv('fruit_flows.csv', 'fruit_processes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These hierarchies and partitions are used later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree_func = nx.DiGraph()\n",
    "tree_func.add_edges_from([\n",
    "        ('*', x) for x in ('inputs', 'composting', 'landfill', 'composting', 'growers', 'consumers')\n",
    "    ] + [\n",
    "        ('growers', x) for x in ('allotment', 'farm')\n",
    "    ] + [\n",
    "        ('farm', x) for x in ('small farm', 'large farm')\n",
    "    ] + [\n",
    "        ('composting', x) for x in ('composting process', 'composting stock')\n",
    "    ])\n",
    "h_func = Hierarchy(tree_func, 'function')\n",
    "\n",
    "farm_ids = ['farm{}'.format(i) for i in range(1, 16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "farm_partition_2 = (Partition([Group('other', [('process', farm_ids[2:])])]) + \n",
    "                   Partition.Simple('process', farm_ids[:2]) \n",
    "                   )\n",
    "\n",
    "farm_partition_5 = (Partition([Group('Other farms', [('process', farm_ids[5:])])]) + \n",
    "                   Partition.Simple('process', farm_ids[:5])\n",
    "                   )\n",
    "\n",
    "partition_fruit = Partition.Simple('material', ['bananas', 'apples', 'oranges'])\n",
    "\n",
    "partition_sector = Partition.Simple('process.sector', ['government', 'industry', 'domestic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "default_margins = {'top': 15, 'right': 80, 'bottom': 5, 'left': 80}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4: Diagram structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one possible Sankey Diagram Definition (SDD) based on the fruit dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nodes = {\n",
    "    'inputs':     ProcessGroup(['inputs']),\n",
    "    'compost':    ProcessGroup(h_func('composting stock')),\n",
    "    'landfill':   ProcessGroup('function == \"landfill\" and location != \"London\"'),\n",
    "    'composting': ProcessGroup(h_func('composting process') + ' and location != \"London\"'),\n",
    "    'farms':      ProcessGroup(h_func('growers')),\n",
    "    'eat':        ProcessGroup('function == \"consumers\" and location != \"London\"'),\n",
    "}\n",
    "ordering = [\n",
    "    ['inputs', 'compost'],\n",
    "    ['farms'],\n",
    "    ['eat'],\n",
    "    ['landfill', 'composting'],\n",
    "]\n",
    "bundles = [\n",
    "    Bundle('eat', 'landfill'),\n",
    "    Bundle('eat', 'composting'),\n",
    "    Bundle('inputs', 'farms'),\n",
    "    Bundle('compost', 'farms'),\n",
    "    Bundle('farms', 'eat'),\n",
    "    Bundle('farms', 'compost'),\n",
    "    Bundle('composting', 'compost'),\n",
    "]\n",
    "sdd = SankeyDefinition(nodes, bundles, ordering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which leads to this Sankey diagram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_sankey(sdd, dataset, width=500, height=250, override_node_layout={\n",
    "        '__farms_compost_1^*': {'y': 0.75},\n",
    "        '__farms_compost_0^*': {'y': 0.75},\n",
    "    }, override_link_layout={\n",
    "        \"__composting_compost_0^*-compost^*-*\": {'r0': 20.5, 'r1': 20.5},\n",
    "    }, margins=default_margins\n",
    ").auto_save_svg('structure_sankey_1.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *The layout overrides are currently experimental and undocumented features of the Sankey layout code.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other options are possible, for example partition together the 'farms' and 'eating' processes, and starting with 'composting' on the left:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nodes = {\n",
    "    'inputs':      ProcessGroup(['inputs']),\n",
    "    'compost':     ProcessGroup(h_func('composting stock')),\n",
    "    'farms & eat': ProcessGroup(h_func('growers', 'consumers')),\n",
    "    'landfill':    ProcessGroup('function == \"landfill\"'),\n",
    "    'composting' : ProcessGroup('function == \"composting process\"'),\n",
    "}\n",
    "ordering = [\n",
    "    ['inputs', 'composting'],\n",
    "    ['compost'],\n",
    "    ['farms & eat'],\n",
    "    ['landfill'],\n",
    "]\n",
    "bundles = [\n",
    "    Bundle('inputs', 'farms & eat'),\n",
    "    Bundle('compost', 'farms & eat'),\n",
    "    Bundle('farms & eat', 'compost'),\n",
    "    Bundle('farms & eat', 'landfill'),\n",
    "    Bundle('farms & eat', 'composting'),\n",
    "    Bundle('composting', 'compost'),\n",
    "]\n",
    "sdd = SankeyDefinition(nodes, bundles, ordering)\n",
    "\n",
    "show_sankey(sdd, dataset, width=500, height=250, override_node_layout={\n",
    "        'compost^*': {'y': 0.55},\n",
    "        'composting^*': {'y': 0.55},\n",
    "        'landfill^*': {'y': 0}\n",
    "    }, margins=default_margins\n",
    ").auto_save_svg('structure_sankey_2.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 5: Partitioning processes\n",
    "\n",
    "The definitions in Figure 4 produce Sankey diagrams without much detail, as all of the underlying processes in each node are grouped together. In fact there is a direct correspondence between the high-level graph and the resulting Sankey digram. To see more detail, we can specify partitions for each node (these are defined above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nodes = {\n",
    "    'inputs':     ProcessGroup(['inputs']),\n",
    "    'compost':    ProcessGroup(h_func('composting stock')),\n",
    "    'farms':      ProcessGroup(h_func('growers'), partition=farm_partition_2, title='farms'),\n",
    "    'eat':        ProcessGroup('function == \"consumers\" and location != \"London\"',\n",
    "                               partition=partition_sector, title='eat'),\n",
    "    'landfill':   ProcessGroup('function == \"landfill\" and location != \"London\"'),\n",
    "    'composting': ProcessGroup('function == \"composting process\" and location != \"London\"'),\n",
    "}\n",
    "ordering = [\n",
    "    ['inputs', 'compost'],\n",
    "    ['farms'],\n",
    "    ['eat'],\n",
    "    ['landfill', 'composting'],\n",
    "]\n",
    "bundles = [\n",
    "    Bundle('inputs', 'farms'),\n",
    "    Bundle('compost', 'farms'),\n",
    "    Bundle('farms', 'eat'),\n",
    "    Bundle('farms', 'compost'),\n",
    "    Bundle('eat', 'landfill'),\n",
    "    Bundle('eat', 'composting'),\n",
    "    Bundle('composting', 'compost'),\n",
    "]\n",
    "sdd = SankeyDefinition(nodes, bundles, ordering)\n",
    "\n",
    "show_sankey(sdd, dataset, width=500, height=250, margins=default_margins\n",
    ").auto_save_svg('partition_processes_sankey.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 6: Waypoints adding extra layers\n",
    "\n",
    "To introduce a new layer between the `farms` and `eat` nodes, we introduce a \"waypoint\" in the bundle from farm to eat. For simplicity, only the part of the Sankey diagram between `farms` and `eat` is shown in this figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "partition_weeks = Partition([\n",
    "    Group(day, [('time', [date(2011, 8, d).strftime('%Y-%m-%d')\n",
    "                          for d in range(1, 32) if date(2011, 8, d).strftime('%a') == day])])\n",
    "    for day in ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "])\n",
    "nodes = {\n",
    "    'farms': ProcessGroup(h_func('growers', 'composting stock'), dataset.partition('source.location'),\n",
    "                          title='farm location'),\n",
    "    'eat':   ProcessGroup(h_func('consumers'), dataset.partition('target.location'), title='consumer location'),\n",
    "    'waypoint1': Waypoint(dataset.partition('material'), title='material'),\n",
    "    'waypoint2': Waypoint(partition_weeks, title='day of week'),\n",
    "    'waypoint3': Waypoint(dataset.partition('target.sector'), title='consumer sector'),\n",
    "\n",
    "}\n",
    "bundles = [\n",
    "    Bundle('farms', 'eat', waypoints=['waypoint1', 'waypoint2', 'waypoint3']),\n",
    "]\n",
    "ordering = [\n",
    "    ['farms'], ['waypoint1'], ['waypoint2'], ['waypoint3'], ['eat'],\n",
    "]\n",
    "sdd = SankeyDefinition(nodes, bundles, ordering)\n",
    "show_sankey(sdd, dataset, width=650, height=250,\n",
    "            margins={'top': 15, 'right': 110, 'bottom': 5, 'left': 80}\n",
    ").auto_save_svg('waypoint_layers_sankey.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7: Partitioning flows\n",
    "So far flows have been distinguished based only on their start and end points in the diagram. Bundles can also be partitioned based on attributes of the underlying flows. Here the flows are partitioned based on the flow `material` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes = {\n",
    "    'farms': ProcessGroup(h_func('growers', 'composting stock'), dataset.partition('source.location')),\n",
    "    'eat':   ProcessGroup(h_func('consumers'), dataset.partition('target.sector')),\n",
    "    'waypoint1': Waypoint(dataset.partition('material')),\n",
    " \n",
    "}\n",
    "bundles = [\n",
    "    Bundle('farms', 'eat', waypoints=['waypoint1',]),\n",
    "]\n",
    "ordering = [\n",
    "    ['farms'], ['waypoint1'], ['eat'],\n",
    "]\n",
    "sdd = SankeyDefinition(nodes, bundles, ordering, flow_partition=partition_fruit)\n",
    "show_sankey(sdd, dataset, width=500, height=250, margins=default_margins\n",
    ").auto_save_svg('partition_flows_sankey_1.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sdd = SankeyDefinition(nodes, bundles, ordering, flow_partition=dataset.partition('source.location'))\n",
    "show_sankey(sdd, dataset, width=500, height=250, margins=default_margins,\n",
    ").auto_save_svg('partition_flows_sankey_2.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 8: Final Sankey diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes = {\n",
    "    'inputs':     ProcessGroup(['inputs'], title='Other inputs'),\n",
    "    'compost':    ProcessGroup(h_func('composting stock'), title='Compost'),\n",
    "    'farms':      ProcessGroup(h_func('growers'), partition=farm_partition_5),\n",
    "    'eat':        ProcessGroup('function == \"consumers\" and location != \"London\"', partition=partition_sector,\n",
    "                      title='consumers by sector'),\n",
    "    'landfill':   ProcessGroup('function == \"landfill\" and location != \"London\"', title='Landfill'),\n",
    "    'composting': ProcessGroup('function == \"composting process\" and location != \"London\"', title='Composting'),\n",
    "\n",
    "    'fruit':        Waypoint(partition_fruit, title='fruit type'),\n",
    "    'w1':           Waypoint(direction='L', title=''),\n",
    "    'w2':           Waypoint(direction='L', title=''),\n",
    "    'export fruit': Waypoint(Partition.Simple('material', ['apples', 'bananas', 'oranges'])),\n",
    "    'exports':      Waypoint(title='Exports'),\n",
    "}\n",
    "ordering = [\n",
    "    [[], ['inputs', 'compost'], []],\n",
    "    [[], ['farms'], ['w2']],\n",
    "    [['exports'], ['fruit'], []],\n",
    "    [[], ['eat'], []],\n",
    "    [['export fruit'], ['landfill', 'composting'], ['w1']],\n",
    "]\n",
    "bundles = [\n",
    "    Bundle('inputs', 'farms'),\n",
    "    Bundle('compost', 'farms'),\n",
    "    Bundle('farms', 'eat', waypoints=['fruit']),\n",
    "    Bundle('farms', 'compost', waypoints=['w2']),\n",
    "    Bundle('eat', 'landfill'),\n",
    "    Bundle('eat', 'composting'),\n",
    "    Bundle('composting', 'compost', waypoints=['w1', 'w2']),\n",
    "    Bundle('farms', Elsewhere, waypoints=['exports', 'export fruit', ]),\n",
    "]\n",
    "sdd = SankeyDefinition(nodes, bundles, ordering, flow_partition=dataset.partition('material'))\n",
    "\n",
    "show_sankey(sdd, dataset, width=800, height=500, override_link_layout={\n",
    "        \"farms^Other farms-w2^*-compost\": {'r0': 12, 'r1': 12},\n",
    "        \"farms^farm1-w2^*-compost\": {'r0': 9, 'r1': 9},\n",
    "        \"farms^farm2-w2^*-compost\": {'r0': 8, 'r1': 8},\n",
    "        \"farms^farm3-w2^*-compost\": {'r0': 7, 'r1': 7},\n",
    "        \"farms^farm4-w2^*-compost\": {'r0': 6, 'r1': 6},\n",
    "        \"farms^farm5-w2^*-compost\": {'r0': 5, 'r1': 5},\n",
    "    }, margins=default_margins\n",
    ").auto_save_svg('final_diagram.svg')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {
   "attach-environment": true,
   "summary": "Generate figures for Sankey diagram paper"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
