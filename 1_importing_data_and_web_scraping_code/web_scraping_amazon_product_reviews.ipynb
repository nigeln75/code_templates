{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'amazon'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-51442b4e3d99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mamazon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAmazonAPI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdateutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'amazon'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import absolute_import\n",
    "import logging\n",
    "import re\n",
    "try:\n",
    "    import urlparse\n",
    "except:\n",
    "    import urllib.parse as urlparse\n",
    "import urllib\n",
    "import functools\n",
    "import time\n",
    "import requests\n",
    "import warnings\n",
    "from amazon.api import AmazonAPI\n",
    "import dateutil.parser\n",
    "from bs4 import BeautifulSoup\n",
    "from .version import __version__  # load our version\n",
    "\n",
    "if 'unicode' not in dir(globals()['__builtins__']):\n",
    "    unicode = str\n",
    "\n",
    "# stop warnings about unused variable\n",
    "__version__\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# fix #1\n",
    "# 'html.parser' has trouble with http://www.amazon.com/product-reviews/B00008MOQA/ref=cm_cr_pr_top_sort_recent?&sortBy=bySubmissionDateDescending\n",
    "# it sometimes doesn't find the asin span\n",
    "html_parser = 'html.parser'\n",
    "#html_parser = 'html5lib'\n",
    "\n",
    "#user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.107 Safari/537.36'\n",
    "user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.94 Safari/537.36'\n",
    "\n",
    "amazon_base = 'http://www.amazon.com'\n",
    "\n",
    "_extract_asin_regexp = re.compile(r'(/dp/|/gp/product/)(?P<asin>[^/]+)/?')\n",
    "_process_rating_regexp = re.compile(r'([\\d\\.]+) out of [\\d\\.]+ stars', flags=re.I)\n",
    "_extract_reviews_asin_regexp = re.compile(r'/product-reviews/(?P<asin>[^/]+)', flags=re.I)\n",
    "_extract_review_id_regexp = re.compile(r'/review/(?P<id>[^/]+)', flags=re.I)\n",
    "_extract_reviewer_id_regexp = re.compile(r'/member-reviews/(?P<id>[^/]+)', flags=re.I)\n",
    "_price_regexp = re.compile(r'(?P<price>[$£][\\d,\\.]+)', flags=re.I)\n",
    "\n",
    "\n",
    "def extract_asin(url):\n",
    "    try:\n",
    "        match = _extract_asin_regexp.search(url)\n",
    "        return str(match.group('asin'))\n",
    "    except:\n",
    "        warnings.warn('Error matching ASIN in URL {}'.format(url))\n",
    "        raise\n",
    "\n",
    "\n",
    "def product_url(asin):\n",
    "    url = '{base}/dp/{asin}'\n",
    "    return url.format(base=amazon_base, asin=asin)\n",
    "\n",
    "\n",
    "def add_affiliate(url, affiliate):\n",
    "    return add_query(url, tag=affiliate)\n",
    "\n",
    "\n",
    "def reviews_url(asin):\n",
    "    url = '{base}/product-reviews/{asin}/ref=cm_cr_pr_top_sort_recent?&sortBy=bySubmissionDateDescending'\n",
    "    return url.format(base=amazon_base, asin=asin)\n",
    "\n",
    "\n",
    "def review_url(id):\n",
    "    url = '{base}/review/{id}'\n",
    "    return url.format(base=amazon_base, id=id)\n",
    "\n",
    "\n",
    "def reviewer_url(id):\n",
    "    url = '{base}/gp/cdp/member-reviews/{id}'\n",
    "    return url.format(base=amazon_base, id=id)\n",
    "\n",
    "\n",
    "def process_rating(text):\n",
    "    \"\"\"The rating normalised to 1.0\n",
    "    \"\"\"\n",
    "    try:\n",
    "        rating_match = _process_rating_regexp.search(text)\n",
    "        return float(rating_match.group(1)) / 5.0\n",
    "    except:\n",
    "        warnings.warn('Error processing rating for text \"{}\"'.format(text))\n",
    "        raise\n",
    "\n",
    "\n",
    "def extract_reviews_asin(url):\n",
    "    try:\n",
    "        match = _extract_reviews_asin_regexp.search(url)\n",
    "        return str(match.group('asin'))\n",
    "    except:\n",
    "        warnings.warn('Error matching reviews ASIN in URL {}'.format(url))\n",
    "        raise\n",
    "\n",
    "\n",
    "def extract_review_id(url):\n",
    "    try:\n",
    "        match = _extract_review_id_regexp.search(url)\n",
    "        return str(match.group('id'))\n",
    "    except:\n",
    "        warnings.warn('Error matching review ID in URL {}'.format(url))\n",
    "        raise\n",
    "\n",
    "\n",
    "def extract_reviewer_id(url):\n",
    "    try:\n",
    "        match = _extract_reviewer_id_regexp.search(url)\n",
    "        return str(match.group('id'))\n",
    "    except:\n",
    "        warnings.warn('Error matching review ID in URL {}'.format(url))\n",
    "        raise\n",
    "\n",
    "\n",
    "def extract_price(text):\n",
    "    try:\n",
    "        match = _price_regexp.search(text)\n",
    "        price = match.group('price')\n",
    "        price = re.sub(r'[$£,]', u'', price)\n",
    "        price = float(price)\n",
    "        return price\n",
    "    except:\n",
    "        warnings.warn('Error extracting price in text \"{}\"'.format(text))\n",
    "        raise\n",
    "\n",
    "\n",
    "def add_query(url, **kwargs):\n",
    "    scheme, netloc, path, query_string, fragment = urlparse.urlsplit(url)\n",
    "    query_params = urlparse.parse_qs(query_string)\n",
    "    # remove any existing value of 'key'\n",
    "    keys = kwargs.keys()\n",
    "    query_params = dict(filter(lambda x: x[0] not in keys, query_params.iteritems()))\n",
    "    query_params.update(kwargs)\n",
    "    query_string = urllib.urlencode(query_params, doseq=True)\n",
    "    return urlparse.urlunsplit((scheme, netloc, path, query_string, fragment))\n",
    "\n",
    "\n",
    "def get_review_date(raw_date):\n",
    "    string = unicode(raw_date)\n",
    "    # 2011-11-07T05:50:41Z\n",
    "    date = dateutil.parser.parse(string)\n",
    "    return date\n",
    "\n",
    "\n",
    "def strip_html_tags(html):\n",
    "    if html:\n",
    "        soup = BeautifulSoup(html, html_parser)\n",
    "        text = soup.findAll(text=True)\n",
    "        text = u'\\n'.join(text).strip()\n",
    "        return text\n",
    "    return None\n",
    "\n",
    "\n",
    "def retry(retries=5, exceptions=None):\n",
    "    if not exceptions:\n",
    "        exceptions = (BaseException,)\n",
    "\n",
    "    def outer(fn):\n",
    "        @functools.wraps(fn)\n",
    "        def decorator(*args, **kwargs):\n",
    "            for attempt in range(1, retries + 1):\n",
    "                try:\n",
    "                    if attempt > 1:\n",
    "                        log.debug('{0}({1}, {2}) - Retry attempt {3}/{4}'.format(fn.__name__, args, kwargs, attempt, retries))\n",
    "                    result = fn(*args, **kwargs)\n",
    "                    return result\n",
    "                except BaseException as e:\n",
    "                    if not isinstance(e, exceptions):\n",
    "                        raise\n",
    "                    if attempt >= retries:\n",
    "                        log.debug('{0}({1}, {2}) - Retry limit exceeded'.format(fn.__name__, args, kwargs))\n",
    "                        raise e\n",
    "        return decorator\n",
    "    return outer\n",
    "\n",
    "\n",
    "def get(url, api):\n",
    "    rate_limit(api)\n",
    "    # verify=False ignores SSL errors\n",
    "    r = requests.get(url, headers={'User-Agent': user_agent}, verify=False)\n",
    "    r.raise_for_status()\n",
    "    return r\n",
    "\n",
    "\n",
    "def is_property(obj, k):\n",
    "    # only accept @property decorated functions\n",
    "    # these can only be detected via the __class__ object\n",
    "    if hasattr(obj.__class__, k):\n",
    "        if isinstance(getattr(obj.__class__, k), property):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def dict_acceptable(obj, k, blacklist=None):\n",
    "    # don't store blacklisted variables\n",
    "    if blacklist and k in blacklist:\n",
    "        return False\n",
    "    # don't store hidden variables\n",
    "    if k.startswith('_'):\n",
    "        return False\n",
    "    return is_property(obj, k)\n",
    "\n",
    "\n",
    "def rate_limit(api):\n",
    "    # apply rate limiting\n",
    "    # this is taken from bottlenose/api.py\n",
    "    bn = api.bottlenose\n",
    "    if bn.MaxQPS:\n",
    "        last_query_time = bn._last_query_time[0]\n",
    "        if last_query_time:\n",
    "            wait_time = 1 / bn.MaxQPS - (time.time() - last_query_time)\n",
    "            if wait_time > 0:\n",
    "                log.debug('Waiting %.3fs to call Amazon API' % wait_time)\n",
    "                time.sleep(wait_time)\n",
    "        bn._last_query_time[0] = time.time()\n",
    "\n",
    "# This schema of imports is non-standard and should change. It will require some re-ordering of\n",
    "# functions inside the package though.\n",
    "from amazon_scraper.product import Product\n",
    "from amazon_scraper.reviews import Reviews\n",
    "from amazon_scraper.review import Review\n",
    "from amazon_scraper.user_reviews import UserReviews\n",
    "\n",
    "\n",
    "class AmazonScraper(object):\n",
    "\n",
    "    def __init__(self, access_key, secret_key, associate_tag, *args, **kwargs):\n",
    "        self.api = AmazonAPI(access_key, secret_key, associate_tag, *args, **kwargs)\n",
    "\n",
    "    def reviews(self, ItemId=None, URL=None):\n",
    "        return Reviews(self, ItemId, URL)\n",
    "\n",
    "    def review(self, Id=None, URL=None):\n",
    "        return Review(self, Id, URL)\n",
    "\n",
    "    def user_reviews(self, Id=None, URL=None):\n",
    "        return UserReviews(self, Id, URL)\n",
    "\n",
    "    def lookup(self, URL=None, **kwargs):\n",
    "        if URL:\n",
    "            kwargs['ItemId'] = extract_asin(URL)\n",
    "\n",
    "        result = self.amazon_simple_api.lookup(**kwargs)\n",
    "        if isinstance(result, (list, tuple)):\n",
    "            result = [Product(self, p) for p in result]\n",
    "        else:\n",
    "            result = Product(self, result)\n",
    "        return result\n",
    "\n",
    "    def similarity_lookup(self, **kwargs):\n",
    "        for p in self.amazon_simple_api.similarity_lookup(**kwargs):\n",
    "            yield Product(self, p)\n",
    "\n",
    "    def browse_node_lookup(self, **kwargs):\n",
    "        return self.amazon_simple_api.browse_node_lookup(**kwargs)\n",
    "\n",
    "    def search(self, **kwargs):\n",
    "        for p in self.amazon_simple_api.search(**kwargs):\n",
    "            yield Product(self, p)\n",
    "\n",
    "    def search_n(self, n, **kwargs):\n",
    "        for p in self.amazon_simple_api.search_n(n, **kwargs):\n",
    "            yield Product(self, p)\n",
    "\n",
    "    @property\n",
    "    def amazon_simple_api(self):\n",
    "        return self.api\n",
    "\n",
    "    @property\n",
    "    def bottlenose(self):\n",
    "        return self.api.api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
