{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from dateutil import parser, rrule\n",
    "from datetime import datetime, time, date\n",
    "import time\n",
    " \n",
    "def getRainfallData(station, day, month, year):\n",
    "    \"\"\"\n",
    "    Function to return a data frame of minute-level weather data for a single Wunderground PWS station.\n",
    "    \n",
    "    Args:\n",
    "        station (string): Station code from the Wunderground website\n",
    "        day (int): Day of month for which data is requested\n",
    "        month (int): Month for which data is requested\n",
    "        year (int): Year for which data is requested\n",
    "    \n",
    "    Returns:\n",
    "        Pandas Dataframe with weather data for specified station and date.\n",
    "    \"\"\"\n",
    "    url = \"http://www.wunderground.com/weatherstation/WXDailyHistory.asp?ID={station}&day={day}&month={month}&year={year}&graphspan=day&format=1\"\n",
    "    full_url = url.format(station=station, day=day, month=month, year=year)\n",
    "    # Request data from wunderground data\n",
    "    response = requests.get(full_url, headers={'User-agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})\n",
    "    data = response.text\n",
    "    # remove the excess <br> from the text data\n",
    "    data = data.replace('<br>', '')\n",
    "    # Convert to pandas dataframe (fails if issues with weather station)\n",
    "    try:\n",
    "        dataframe = pd.read_csv(io.StringIO(data), index_col=False)\n",
    "        dataframe['station'] = station\n",
    "    except Exception as e:\n",
    "        print(\"Issue with date: {}-{}-{} for station {}\".format(day,month,year, station))\n",
    "        return None\n",
    "    return dataframe\n",
    "    \n",
    "# Generate a list of all of the dates we want data for\n",
    "start_date = \"2015-01-01\"\n",
    "end_date = \"2015-12-31\"\n",
    "start = parser.parse(start_date)\n",
    "end = parser.parse(end_date)\n",
    "dates = list(rrule.rrule(rrule.DAILY, dtstart=start, until=end))\n",
    " \n",
    "# Create a list of stations here to download data for\n",
    "stations = [\"IDUBLINF3\", \"IDUBLINF2\", \"ICARRAIG2\", \"IGALWAYR2\", \"IBELFAST4\", \"ILONDON59\", \"IILEDEFR28\"]\n",
    "# Set a backoff time in seconds if a request fails\n",
    "backoff_time = 10\n",
    "data = {}\n",
    " \n",
    "# Gather data for each station in turn and save to CSV.\n",
    "for station in stations:\n",
    "    print(\"Working on {}\".format(station))\n",
    "    data[station] = []\n",
    "    for date in dates:\n",
    "        # Print period status update messages\n",
    "        if date.day % 10 == 0:\n",
    "            print(\"Working on date: {} for station {}\".format(date, station))\n",
    "        done = False\n",
    "        while done == False:\n",
    "            try:\n",
    "                weather_data = getRainfallData(station, date.day, date.month, date.year)\n",
    "                done = True\n",
    "            except ConnectionError as e:\n",
    "                # May get rate limited by Wunderground.com, backoff if so.\n",
    "                print(\"Got connection error on {}\".format(date))\n",
    "                print(\"Will retry in {} seconds\".format(backoff_time))\n",
    "                time.sleep(10)\n",
    "        # Add each processed date to the overall data\n",
    "        data[station].append(weather_data)\n",
    "    # Finally combine all of the individual days and output to CSV for analysis.\n",
    "    pd.concat(data[station]).to_csv(\"data/{}_weather.csv\".format(station))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "station = 'IEDINBUR6' # Edinburgh\n",
    "data_input = pd.read_csv('data/{}_weather.csv'.format(station))\n",
    " \n",
    "# Give the variables some friendlier names and convert types as necessary.\n",
    "data_raw['temp'] = data_raw['TemperatureC'].astype(float)\n",
    "data_raw['rain'] = data_raw['HourlyPrecipMM'].astype(float)\n",
    "data_raw['total_rain'] = data_raw['dailyrainMM'].astype(float)\n",
    "data_raw['date'] = data_raw['DateUTC'].apply(parser.parse)\n",
    "data_raw['humidity'] = data_raw['Humidity'].astype(float)\n",
    "data_raw['wind_direction'] = data_raw['WindDirectionDegrees']\n",
    "data_raw['wind'] = data_raw['WindSpeedKMH']\n",
    " \n",
    "# Extract out only the data we need.\n",
    "data = data_raw.loc[:, ['date', 'station', 'temp', 'rain', 'total_rain', 'humidity', 'wind']]\n",
    "data = data[(data['date'] >= datetime(2015,1,1)) & (data['date'] <= datetime(2015,12,31))]\n",
    " \n",
    "# There's an issue with some stations that record rainfall ~-2500 where data is missing.\n",
    "if (data['rain'] < -500).sum() > 10:\n",
    "    print(\"There's more than 10 messed up days for {}\".format(station))\n",
    "    \n",
    "# remove the bad samples\n",
    "data = data[data['rain'] > -500]\n",
    " \n",
    "# Assign the \"day\" to every date entry\n",
    "data['day'] = data['date'].apply(lambda x: x.date())\n",
    " \n",
    "# Get the time, day, and hour of each timestamp in the dataset\n",
    "data['time_of_day'] = data['date'].apply(lambda x: x.time())\n",
    "data['day_of_week'] = data['date'].apply(lambda x: x.weekday())    \n",
    "data['hour_of_day'] = data['time_of_day'].apply(lambda x: x.hour)\n",
    "# Mark the month for each entry so we can look at monthly patterns\n",
    "data['month'] = data['date'].apply(lambda x: x.month)\n",
    " \n",
    "# Is each time stamp on a working day (Mon-Fri)\n",
    "data['working_day'] = (data['day_of_week'] >= 0) & (data['day_of_week'] <= 4)\n",
    " \n",
    "# Classify into morning or evening times (assuming travel between 8.15-9am and 5.15-6pm)\n",
    "data['morning'] = (data['time_of_day'] >= time(8,15)) & (data['time_of_day'] <= time(9,0))\n",
    "data['evening'] = (data['time_of_day'] >= time(17,15)) & (data['time_of_day'] <= time(18,0))\n",
    " \n",
    "# If there's any rain at all, mark that!\n",
    "data['raining'] = data['rain'] > 0.0\n",
    " \n",
    "# You get wet cycling if its a working day, and its raining at the travel times!\n",
    "data['get_wet_cycling'] = (data['working_day']) & ((data['morning'] & data['rain']) |\n",
    "                                                   (data['evening'] & data['rain']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Looking at the working days only and create a daily data set of working days:\n",
    "wet_cycling = data[data['working_day'] == True].groupby('day')['get_wet_cycling'].any()\n",
    "wet_cycling = pd.DataFrame(wet_cycling).reset_index()\n",
    " \n",
    "# Group by month for display - monthly data set for plots.\n",
    "wet_cycling['month'] = wet_cycling['day'].apply(lambda x: x.month)\n",
    "monthly = wet_cycling.groupby('month')['get_wet_cycling'].value_counts().reset_index()\n",
    "monthly.rename(columns={\"get_wet_cycling\":\"Rainy\", 0:\"Days\"}, inplace=True)\n",
    "monthly.replace({\"Rainy\": {True: \"Wet\", False:\"Dry\"}}, inplace=True)    \n",
    "monthly['month_name'] = monthly['month'].apply(lambda x: calendar.month_abbr[x])\n",
    " \n",
    "# Get aggregate stats for each day in the dataset on rain in general - for heatmaps.\n",
    "rainy_days = data.groupby(['day']).agg({\n",
    "        \"rain\": {\"rain\": lambda x: (x > 0.0).any(),\n",
    "                 \"rain_amount\": \"sum\"},\n",
    "        \"total_rain\": {\"total_rain\": \"max\"},\n",
    "        \"get_wet_cycling\": {\"get_wet_cycling\": \"any\"}\n",
    "        })    \n",
    " \n",
    "# clean up the aggregated data to a more easily analysed set:\n",
    "rainy_days.reset_index(drop=False, inplace=True) # remove the 'day' as the index\n",
    "rainy_days.rename(columns={\"\":\"date\"}, inplace=True) # The old index column didn't have a name - add \"date\" as name\n",
    "rainy_days.columns = rainy_days.columns.droplevel(level=0) # The aggregation left us with a multi-index\n",
    "                                                           # Remove the top level of this index.\n",
    "rainy_days['rain'] = rainy_days['rain'].astype(bool)       # Change the \"rain\" column to True/False values\n",
    " \n",
    "# Add the number of rainy hours per day this to the rainy_days dataset.\n",
    "temp = data.groupby([\"day\", \"hour_of_day\"])['raining'].any()\n",
    "temp = temp.groupby(level=[0]).sum().reset_index()\n",
    "temp.rename(columns={'raining': 'hours_raining'}, inplace=True)\n",
    "temp['day'] = temp['day'].apply(lambda x: x.to_datetime().date())\n",
    "rainy_days = rainy_days.merge(temp, left_on='date', right_on='day', how='left')\n",
    "rainy_days.drop('day', axis=1, inplace=True)\n",
    " \n",
    "print \"In the year, there were {} rainy days of {} at {}\".format(rainy_days['rain'].sum(), len(rainy_days), station)    \n",
    "print \"It was wet while cycling {} working days of {} at {}\".format(wet_cycling['get_wet_cycling'].sum(), \n",
    "                                                      len(wet_cycling),\n",
    "                                                     station)\n",
    "print \"You get wet cycling {} % of the time!!\".format(wet_cycling['get_wet_cycling'].sum()*1.0*100/len(wet_cycling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Monthly plot of rainy days\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\", font_scale=2)\n",
    "sns.barplot(x=\"month_name\", y=\"Days\", hue=\"Rainy\", data=monthly.sort_values(['month', 'Rainy']))\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Number of Days\")\n",
    "plt.title(\"Wet or Dry Commuting in {}\".format(station))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import calmap\n",
    " \n",
    "temp = rainy_days.copy().set_index(pd.DatetimeIndex(analysis['rainy_days']['date']))\n",
    "#temp.set_index('date', inplace=True)\n",
    "fig, ax = calmap.calendarplot(temp['hours_raining'], fig_kws={\"figsize\":(15,4)})\n",
    "plt.title(\"Hours raining\")\n",
    "fig, ax = calmap.calendarplot(temp['total_rain'], fig_kws={\"figsize\":(15,4)})\n",
    "plt.title(\"Total Rainfall Daily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyse_station(data_raw, station):\n",
    "    \"\"\"\n",
    "    Function to analyse weather data for a period from one weather station.\n",
    "    \n",
    "    Args:\n",
    "        data_raw (pd.DataFrame): Pandas Dataframe made from CSV downloaded from wunderground.com\n",
    "        station (String): Name of station being analysed (for comments)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary with analysis in keys:\n",
    "            data: Processed and cleansed data\n",
    "            monthly: Monthly aggregated statistics on rainfall etc.\n",
    "            wet_cycling: Data on working days and whether you get wet or not commuting\n",
    "            rainy_days: Daily total rainfall for each day in dataset.\n",
    "    \"\"\"\n",
    "    # Give the variables some friendlier names and convert types as necessary.\n",
    "    data_raw['temp'] = data_raw['TemperatureC'].astype(float)\n",
    "    data_raw['rain'] = data_raw['HourlyPrecipMM'].astype(float)\n",
    "    data_raw['total_rain'] = data_raw['dailyrainMM'].astype(float)\n",
    "    data_raw['date'] = data_raw['DateUTC'].apply(parser.parse)\n",
    "    data_raw['humidity'] = data_raw['Humidity'].astype(float)\n",
    "    data_raw['wind_direction'] = data_raw['WindDirectionDegrees']\n",
    "    data_raw['wind'] = data_raw['WindSpeedKMH']\n",
    "    \n",
    "    # Extract out only the data we need.\n",
    "    data = data_raw.loc[:, ['date', 'station', 'temp', 'rain', 'total_rain', 'humidity', 'wind']]\n",
    "    data = data[(data['date'] >= datetime(2015,1,1)) & (data['date'] <= datetime(2015,12,31))]\n",
    "    \n",
    "    # There's an issue with some stations that record rainfall ~-2500 where data is missing.\n",
    "    if (data['rain'] < -500).sum() > 10:\n",
    "        print(\"There's more than 10 messed up days for {}\".format(station))\n",
    "        \n",
    "    # remove the bad samples\n",
    "    data = data[data['rain'] > -500]\n",
    " \n",
    "    # Assign the \"day\" to every date entry\n",
    "    data['day'] = data['date'].apply(lambda x: x.date())\n",
    " \n",
    "    # Get the time, day, and hour of each timestamp in the dataset\n",
    "    data['time_of_day'] = data['date'].apply(lambda x: x.time())\n",
    "    data['day_of_week'] = data['date'].apply(lambda x: x.weekday())    \n",
    "    data['hour_of_day'] = data['time_of_day'].apply(lambda x: x.hour)\n",
    "    # Mark the month for each entry so we can look at monthly patterns\n",
    "    data['month'] = data['date'].apply(lambda x: x.month)\n",
    " \n",
    "    # Is each time stamp on a working day (Mon-Fri)\n",
    "    data['working_day'] = (data['day_of_week'] >= 0) & (data['day_of_week'] <= 4)\n",
    " \n",
    "    # Classify into morning or evening times (assuming travel between 8.15-9am and 5.15-6pm)\n",
    "    data['morning'] = (data['time_of_day'] >= time(8,15)) & (data['time_of_day'] <= time(9,0))\n",
    "    data['evening'] = (data['time_of_day'] >= time(17,15)) & (data['time_of_day'] <= time(18,0))\n",
    " \n",
    "    # If there's any rain at all, mark that!\n",
    "    data['raining'] = data['rain'] > 0.0\n",
    " \n",
    "    # You get wet cycling if its a working day, and its raining at the travel times!\n",
    "    data['get_wet_cycling'] = (data['working_day']) & ((data['morning'] & data['rain']) |\n",
    "                                                       (data['evening'] & data['rain']))\n",
    "    # Looking at the working days only:\n",
    "    wet_cycling = data[data['working_day'] == True].groupby('day')['get_wet_cycling'].any()\n",
    "    wet_cycling = pd.DataFrame(wet_cycling).reset_index()\n",
    "    \n",
    "    # Group by month for display\n",
    "    wet_cycling['month'] = wet_cycling['day'].apply(lambda x: x.month)\n",
    "    monthly = wet_cycling.groupby('month')['get_wet_cycling'].value_counts().reset_index()\n",
    "    monthly.rename(columns={\"get_wet_cycling\":\"Rainy\", 0:\"Days\"}, inplace=True)\n",
    "    monthly.replace({\"Rainy\": {True: \"Wet\", False:\"Dry\"}}, inplace=True)    \n",
    "    monthly['month_name'] = monthly['month'].apply(lambda x: calendar.month_abbr[x])\n",
    "    \n",
    "    # Get aggregate stats for each day in the dataset.\n",
    "    rainy_days = data.groupby(['day']).agg({\n",
    "            \"rain\": {\"rain\": lambda x: (x > 0.0).any(),\n",
    "                     \"rain_amount\": \"sum\"},\n",
    "            \"total_rain\": {\"total_rain\": \"max\"},\n",
    "            \"get_wet_cycling\": {\"get_wet_cycling\": \"any\"}\n",
    "            })    \n",
    "    rainy_days.reset_index(drop=False, inplace=True)\n",
    "    rainy_days.columns = rainy_days.columns.droplevel(level=0)\n",
    "    rainy_days['rain'] = rainy_days['rain'].astype(bool)\n",
    "    rainy_days.rename(columns={\"\":\"date\"}, inplace=True)               \n",
    "    \n",
    "    # Also get the number of hours per day where its raining, and add this to the rainy_days dataset.\n",
    "    temp = data.groupby([\"day\", \"hour_of_day\"])['raining'].any()\n",
    "    temp = temp.groupby(level=[0]).sum().reset_index()\n",
    "    temp.rename(columns={'raining': 'hours_raining'}, inplace=True)\n",
    "    temp['day'] = temp['day'].apply(lambda x: x.to_datetime().date())\n",
    "    rainy_days = rainy_days.merge(temp, left_on='date', right_on='day', how='left')\n",
    "    rainy_days.drop('day', axis=1, inplace=True)\n",
    "    \n",
    "    print \"In the year, there were {} rainy days of {} at {}\".format(rainy_days['rain'].sum(), len(rainy_days), station)    \n",
    "    print \"It was wet while cycling {} working days of {} at {}\".format(wet_cycling['get_wet_cycling'].sum(), \n",
    "                                                          len(wet_cycling),\n",
    "                                                         station)\n",
    "    print \"You get wet cycling {} % of the time!!\".format(wet_cycling['get_wet_cycling'].sum()*1.0*100/len(wet_cycling))\n",
    " \n",
    "    return {\"data\":data, 'monthly':monthly, \"wet_cycling\":wet_cycling, 'rainy_days': rainy_days}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load up each of the stations into memory.\n",
    "stations = [\n",
    " (\"IAMSTERD55\", \"Amsterdam\"),\n",
    " (\"IBCNORTH17\", \"Vancouver\"),\n",
    " (\"IBELFAST4\", \"Belfast\"),\n",
    " (\"IBERLINB54\", \"Berlin\"),\n",
    " (\"ICOGALWA4\", \"Galway\"),\n",
    " (\"ICOMUNID56\", \"Madrid\"),\n",
    " (\"IDUBLIND35\", \"Dublin\"),\n",
    " (\"ILAZIORO71\", \"Rome\"),\n",
    " (\"ILEDEFRA6\", \"Paris\"),\n",
    " (\"ILONDONL28\", \"London\"),\n",
    " (\"IMUNSTER11\", \"Cork\"),\n",
    " (\"INEWSOUT455\", \"Sydney\"),\n",
    " (\"ISOPAULO61\", \"Sao Paulo\"),\n",
    " (\"IWESTERN99\", \"Cape Town\"),\n",
    " (\"KCASANFR148\", \"San Francisco\"),\n",
    " (\"KNYBROOK40\", \"New York\"),\n",
    " (\"IRENFREW4\", \"Glasgow\"),\n",
    " (\"IENGLAND64\", \"Liverpool\"),\n",
    " ('IEDINBUR6', 'Edinburgh')\n",
    "]\n",
    "data = []\n",
    "for station in stations:\n",
    "   weather = {}\n",
    "   print \"Loading data for station: {}\".format(station[1])\n",
    "   weather['data'] = pd.DataFrame.from_csv(\"data/{}_weather.csv\".format(station[0]))\n",
    "   weather['station'] = station[0]\n",
    "   weather['name'] = station[1]\n",
    "   data.append(weather)\n",
    " \n",
    "for ii in range(len(data)):\n",
    "    print \"Processing data for {}\".format(data[ii]['name'])\n",
    "    data[ii]['result'] = analyse_station(data[ii]['data'], data[ii]['station'])\n",
    " \n",
    "# Now extract the number of wet days, the number of wet cycling days, and the number of wet commutes for a single chart.\n",
    "output = []\n",
    "for ii in range(len(data)):\n",
    "    temp = {\n",
    "            \"total_wet_days\": data[ii]['result']['rainy_days']['rain'].sum(),\n",
    "            \"wet_commutes\": data[ii]['result']['wet_cycling']['get_wet_cycling'].sum(),\n",
    "            \"commutes\": len(data[ii]['result']['wet_cycling']),\n",
    "            \"city\": data[ii]['name']\n",
    "        }\n",
    "    temp['percent_wet_commute'] = (temp['wet_commutes'] *1.0 / temp['commutes'])*100\n",
    "    output.append(temp)\n",
    "output = pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate plot of percentage of wet commutes\n",
    "plt.figure(figsize=(20,8))\n",
    "sns.set_style(\"whitegrid\")    # Set style for seaborn output\n",
    "sns.set_context(\"notebook\", font_scale=2)\n",
    "sns.barplot(x=\"city\", y=\"percent_wet_commute\", data=output.sort_values('percent_wet_commute', ascending=False))\n",
    "plt.xlabel(\"City\")\n",
    "plt.ylabel(\"Percentage of Wet Commutes (%)\")\n",
    "plt.suptitle(\"What percentage of your cycles to work do you need a raincoat?\", y=1.05, fontsize=32)\n",
    "plt.title(\"Based on Wundergroud.com weather data for 2015\", fontsize=18)\n",
    "plt.xticks(rotation=60)\n",
    "plt.savefig(\"images/city_comparison_wet_commutes.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
