{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import set_option\n",
    "# Restrict Pandas output to 20 rows\n",
    "set_option(\"display.max_rows\",20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-e001c18cf59d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# The second line stores the name of the current directory in a string called wd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# The third outputs the contents of the directory in a list to the shell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wd' is not defined"
     ]
    }
   ],
   "source": [
    "# The first line of the following code imports the library os\n",
    "import os\n",
    "# The second line stores the name of the current directory in a string called wd\n",
    "os.listdir(wd)\n",
    "# The third outputs the contents of the directory in a list to the shell\n",
    "wd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can see what file formats you read in using Pandas by hitting tab\n",
    "pd.read_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hit shift enter with ? to see help!!!\n",
    "pd.read_table?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in HDF5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hierarchical data format v5 files are becoming the standard format for storing large quantities of numerical data\n",
    "# HDF5 can scale to Exabytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# Assign filename: file\n",
    "file = 'LIGO_data.hdf5'\n",
    "\n",
    "# Load file: data\n",
    "data = h5py.File(file, 'r')\n",
    "\n",
    "# Print the datatype of the loaded file\n",
    "print(type(data))\n",
    "\n",
    "# Print the keys of the file\n",
    "for key in data.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the HDF5 group: group\n",
    "group = data['strain']\n",
    "\n",
    "# Check out keys of group\n",
    "for key in group.keys():\n",
    "    print(key)\n",
    "\n",
    "# Set variable equal to time series data: strain\n",
    "strain = data['strain']['Strain'].value\n",
    "\n",
    "# Set number of time points to sample: num_samples\n",
    "num_samples = 10000\n",
    "\n",
    "# Set time vector\n",
    "time = np.arange(0, 1, 1/num_samples)\n",
    "\n",
    "# Plot data\n",
    "plt.plot(time, strain[:num_samples])\n",
    "plt.xlabel('GPS Time (s)')\n",
    "plt.ylabel('strain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in SAS files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'sas7bdat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f079f642b66c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msas7bdat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSAS7BDAT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'sas7bdat'"
     ]
    }
   ],
   "source": [
    "# Import sas7bdat package\n",
    "from sas7bdat import SAS7BDAT\n",
    "\n",
    "# Save file to a DataFrame: df_sas\n",
    "with SAS7BDAT('sales.sas7bdat') as file:\n",
    "    df_sas = file.to_data_frame()\n",
    "\n",
    "# Print head of DataFrame\n",
    "print(df_sas.head())\n",
    "\n",
    "# Plot histogram of DataFrame features (pandas and pyplot already imported)\n",
    "pd.DataFrame.hist(df_sas[['P']])\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Matlab files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Matlab stands for Matrix Laboratory\n",
    "# Data is saved as .mat files\n",
    "# Scipy has standard libraries for reading in Matlab files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import package\n",
    "import scipy.io\n",
    "\n",
    "# Load MATLAB file: mat\n",
    "mat = scipy.io.loadmat('albeck_gene_expression.mat')\n",
    "\n",
    "# Print the datatype type of mat\n",
    "print(type(mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print the keys of the MATLAB dictionary\n",
    "# Most of these keys (in fact the ones that do NOT begin and end with '__') are variables from the corresponding MATLAB environment.\n",
    "print(mat.keys())\n",
    "\n",
    "# Print the type of the value corresponding to the key 'CYratioCyt'\n",
    "print(type(mat['CYratioCyt']))\n",
    "\n",
    "# Print the shape of the value corresponding to the key 'CYratioCyt'\n",
    "print(np.shape(mat['CYratioCyt']))\n",
    "\n",
    "# Subset the array and plot it\n",
    "data = mat['CYratioCyt'][25, 5:]\n",
    "fig = plt.figure()\n",
    "plt.plot(data)\n",
    "plt.xlabel('time (min.)')\n",
    "plt.ylabel('normalized fluorescence (measure of expression)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Stata files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load Stata file into a pandas DataFrame: df\n",
    "df = pd.read_stata('disarea.dta')\n",
    "\n",
    "# Print the head of the DataFrame df\n",
    "print(df.head())\n",
    "\n",
    "# Plot histogram of one column of the DataFrame\n",
    "pd.DataFrame.hist(df[['disa10']])\n",
    "plt.xlabel('Extent of disease')\n",
    "plt.ylabel('Number of coutries')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you want your files to be human readable, you may want to save them as text files in a clever manner (JSONs, which you will see in a later chapter, are appropriate for Python dictionaries).\n",
    "# If, however, you merely want to be able to import them into Python, you can serialize them \n",
    "# All this means is converting the object into a sequence of bytes, or bytestream\n",
    "# Import pickle package\n",
    "import pickle\n",
    "\n",
    "# Open pickle file and load data: d\n",
    "# This argument will be a string of two letters, one signifying 'read only', the other 'binary\n",
    "with open('data.pkl', 'rb') as file:\n",
    "    d = pickle.load(file)\n",
    "\n",
    "# Print d\n",
    "print(d)\n",
    "\n",
    "# Print datatype of d\n",
    "print(type(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listing sheets of Excel spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Assign spreadsheet filename: file\n",
    "file = 'battledeath.xlsx'\n",
    "\n",
    "# Load spreadsheet: xl\n",
    "xl = pd.ExcelFile(file)\n",
    "\n",
    "# Print sheet names\n",
    "print(xl.sheet_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing sheets of Excel spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load a sheet into a DataFrame by name: df1\n",
    "df1 = xl.parse('2004')\n",
    "\n",
    "# Print the head of the DataFrame df1\n",
    "print(df1.head())\n",
    "\n",
    "# Load a sheet into a DataFrame by index: df2\n",
    "df2 = xl.parse(0)\n",
    "\n",
    "# Print the head of the DataFrame df2\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parse the first sheet and rename the columns: df1\n",
    "df1 = xl.parse(0, skiprows=[0], names=['Country','AAM due to War (2002)'])\n",
    "\n",
    "# Print the head of the DataFrame df1\n",
    "print(df1.head())\n",
    "\n",
    "# Parse the first column of the second sheet and rename the column: df2\n",
    "df2 = xl.parse(1, parse_cols=([0]), skiprows=1, names=['Country'])\n",
    "\n",
    "# Print the head of the DataFrame df2\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in the Energy spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Energy']\n",
      "          Country  Energy Supply  Energy Supply per Capita  % Renewable\n",
      "0     Afghanistan          321.0                      10.0    78.669280\n",
      "1         Albania          102.0                      35.0   100.000000\n",
      "2         Algeria         1959.0                      51.0     0.551010\n",
      "3  American Samoa            NaN                       NaN     0.641026\n",
      "4         Andorra            9.0                     121.0    88.695650\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assign spreadsheet filename: file\n",
    "file = 'http://unstats.un.org/unsd/environment/excel_file_tables/2013/Energy%20Indicators.xls'\n",
    "\n",
    "# Load spreadsheet: xl\n",
    "energy_xl = pd.ExcelFile(file)\n",
    "\n",
    "# Print sheet names\n",
    "print(energy_xl.sheet_names)\n",
    "\n",
    "# Load a sheet into a DataFrame by name: df1\n",
    "energy_df = energy_xl.parse('Energy', parse_cols=([2,3,4,5]), \n",
    "                            skiprows = 17, \n",
    "                            names=['Country', 'Energy Supply', 'Energy Supply per Capita', '% Renewable'])\n",
    "\n",
    "energy_df = energy_df[:-38]\n",
    "\n",
    "energy_df = energy_df.applymap(lambda x: np.nan if x == '...' else x)\n",
    "\n",
    "# Remove any digits from country name\n",
    "# e.g. 'Bolivia (Plurinational State of)'` should be `'Bolivia'`, 'Switzerland17'` should be `'Switzerland'`\n",
    "\n",
    "import string\n",
    "translation = str.maketrans(string.ascii_letters, string.ascii_letters, string.digits)\n",
    "energy_df['Country'] = energy_df.Country.str.translate(translation)\n",
    "energy_df['Country'] = energy_df.Country.str.strip()\n",
    "\n",
    "# Remove text within parentheses\n",
    "# There are also several countries with numbers and/or parenthesis in their name. Be sure to remove these, \n",
    "energy_df['Country'] = energy_df['Country'].str.replace(r\"\\(.*\\)\",\"\")\n",
    "\n",
    "country_lookup = {\"Republic of Korea\": \"South Korea\",\"United States of America\": \"United States\",\n",
    "                  \"United Kingdom of Great Britain and Northern Ireland\": \"United Kingdom\",\n",
    "                  \"China, Hong Kong Special Administrative Region\": \"Hong Kong\"}\n",
    "energy_df = energy_df.replace({\"Country\": country_lookup})\n",
    "\n",
    "# Print the head of the DataFrame df1\n",
    "print(energy_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Country  Energy Supply  Energy Supply per Capita  % Renewable\n",
      "197  Switzerland         1113.0                     136.0     57.74548\n"
     ]
    }
   ],
   "source": [
    "print(energy_df[energy_df['Country'].str.contains(\"Switz\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Country  Energy Supply  Energy Supply per Capita  \\\n",
      "222                   Viet Nam         2554.0                      28.0   \n",
      "223  Wallis and Futuna Islands            0.0                      26.0   \n",
      "224                      Yemen          344.0                      13.0   \n",
      "225                     Zambia          400.0                      26.0   \n",
      "226                   Zimbabwe          480.0                      32.0   \n",
      "\n",
      "     % Renewable  \n",
      "222     45.32152  \n",
      "223      0.00000  \n",
      "224      0.00000  \n",
      "225     99.71467  \n",
      "226     52.53612  \n"
     ]
    }
   ],
   "source": [
    "# Print the tail of the DataFrame df1\n",
    "print(energy_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Country  Energy Supply  Energy Supply per Capita  % Renewable\n",
      "164   South Korea        11007.0                     221.0     2.279353\n",
      "188  South Africa         6341.0                     119.0     1.687019\n",
      "189   South Sudan           28.0                       2.0     0.423729\n",
      "                          Country  Energy Supply  Energy Supply per Capita  \\\n",
      "213          United Arab Emirates         2710.0                     300.0   \n",
      "214                United Kingdom         7920.0                     124.0   \n",
      "215   United Republic of Tanzania          994.0                      20.0   \n",
      "216                 United States        90838.0                     286.0   \n",
      "217  United States Virgin Islands            NaN                       NaN   \n",
      "\n",
      "     % Renewable  \n",
      "213      0.00000  \n",
      "214     10.60047  \n",
      "215     31.07284  \n",
      "216     11.57098  \n",
      "217      0.00000  \n",
      "         Country  Energy Supply  Energy Supply per Capita  % Renewable\n",
      "197  Switzerland         1113.0                     136.0     57.74548\n",
      "      Country  Energy Supply  Energy Supply per Capita  % Renewable\n",
      "43  Hong Kong          585.0                      82.0          0.0\n",
      "     Country  Energy Supply  Energy Supply per Capita  % Renewable\n",
      "24  Bolivia           336.0                      32.0     31.47712\n"
     ]
    }
   ],
   "source": [
    "# Checks on countries\n",
    "print(energy_df[energy_df['Country'].str.contains(\"South\")])\n",
    "print(energy_df[energy_df['Country'].str.contains(\"United\")])\n",
    "print(energy_df[energy_df['Country'].str.contains(\"Switz\")])\n",
    "print(energy_df[energy_df['Country'].str.contains(\"Hong Kong\")])\n",
    "print(energy_df[energy_df['Country'].str.contains(\"Bolivia\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Afghanistan' 'Albania' 'Algeria' 'American Samoa' 'Andorra' 'Angola'\n",
      " 'Anguilla' 'Antigua and Barbuda' 'Argentina' 'Armenia' 'Aruba' 'Australia'\n",
      " 'Austria' 'Azerbaijan' 'Bahamas' 'Bahrain' 'Bangladesh' 'Barbados'\n",
      " 'Belarus' 'Belgium' 'Belize' 'Benin' 'Bermuda' 'Bhutan' 'Bolivia '\n",
      " 'Bonaire, Sint Eustatius and Saba' 'Bosnia and Herzegovina' 'Botswana'\n",
      " 'Brazil' 'British Virgin Islands' 'Brunei Darussalam' 'Bulgaria'\n",
      " 'Burkina Faso' 'Burundi' 'Cabo Verde' 'Cambodia' 'Cameroon' 'Canada'\n",
      " 'Cayman Islands' 'Central African Republic' 'Chad' 'Chile' 'China'\n",
      " 'Hong Kong' 'China, Macao Special Administrative Region' 'Colombia'\n",
      " 'Comoros' 'Congo' 'Cook Islands' 'Costa Rica' \"Côte d'Ivoire\" 'Croatia'\n",
      " 'Cuba' 'Curaçao' 'Cyprus' 'Czech Republic'\n",
      " \"Democratic People's Republic of Korea\" 'Democratic Republic of the Congo'\n",
      " 'Denmark' 'Djibouti' 'Dominica' 'Dominican Republic' 'Ecuador' 'Egypt'\n",
      " 'El Salvador' 'Equatorial Guinea' 'Eritrea' 'Estonia' 'Ethiopia'\n",
      " 'Faeroe Islands' 'Falkland Islands ' 'Fiji' 'Finland' 'France'\n",
      " 'French Guiana' 'French Polynesia' 'Gabon' 'Gambia' 'Georgia' 'Germany'\n",
      " 'Ghana' 'Gibraltar' 'Greece' 'Greenland' 'Grenada' 'Guadeloupe' 'Guam'\n",
      " 'Guatemala' 'Guernsey' 'Guinea' 'Guinea-Bissau' 'Guyana' 'Haiti'\n",
      " 'Honduras' 'Hungary' 'Iceland' 'India' 'Indonesia' 'Iran ' 'Iraq'\n",
      " 'Ireland' 'Isle of Man' 'Israel' 'Italy' 'Jamaica' 'Japan' 'Jersey'\n",
      " 'Jordan' 'Kazakhstan' 'Kenya' 'Kiribati' 'Kuwait' 'Kyrgyzstan'\n",
      " \"Lao People's Democratic Republic\" 'Latvia' 'Lebanon' 'Lesotho' 'Liberia'\n",
      " 'Libya' 'Liechtenstein' 'Lithuania' 'Luxembourg' 'Madagascar' 'Malawi'\n",
      " 'Malaysia' 'Maldives' 'Mali' 'Malta' 'Marshall Islands' 'Martinique'\n",
      " 'Mauritania' 'Mauritius' 'Mexico' 'Micronesia ' 'Mongolia' 'Montenegro'\n",
      " 'Montserrat' 'Morocco' 'Mozambique' 'Myanmar' 'Namibia' 'Nauru' 'Nepal'\n",
      " 'Netherlands' 'New Caledonia' 'New Zealand' 'Nicaragua' 'Niger' 'Nigeria'\n",
      " 'Niue' 'Northern Mariana Islands' 'Norway' 'Oman' 'Pakistan' 'Palau'\n",
      " 'Panama' 'Papua New Guinea' 'Paraguay' 'Peru' 'Philippines' 'Poland'\n",
      " 'Portugal' 'Puerto Rico' 'Qatar' 'South Korea' 'Republic of Moldova'\n",
      " 'Réunion' 'Romania' 'Russian Federation' 'Rwanda' 'Saint Helena'\n",
      " 'Saint Kitts and Nevis' 'Saint Lucia' 'Saint Pierre and Miquelon'\n",
      " 'Saint Vincent and the Grenadines' 'Samoa' 'Sao Tome and Principe'\n",
      " 'Saudi Arabia' 'Senegal' 'Serbia' 'Seychelles' 'Sierra Leone' 'Singapore'\n",
      " 'Sint Maarten ' 'Slovakia' 'Slovenia' 'Solomon Islands' 'Somalia'\n",
      " 'South Africa' 'South Sudan' 'Spain' 'Sri Lanka' 'State of Palestine'\n",
      " 'Sudan' 'Suriname' 'Swaziland' 'Sweden' 'Switzerland'\n",
      " 'Syrian Arab Republic' 'Tajikistan' 'Thailand'\n",
      " 'The former Yugoslav Republic of Macedonia' 'Timor-Leste' 'Togo' 'Tonga'\n",
      " 'Trinidad and Tobago' 'Tunisia' 'Turkey' 'Turkmenistan'\n",
      " 'Turks and Caicos Islands' 'Tuvalu' 'Uganda' 'Ukraine'\n",
      " 'United Arab Emirates' 'United Kingdom' 'United Republic of Tanzania'\n",
      " 'United States' 'United States Virgin Islands' 'Uruguay' 'Uzbekistan'\n",
      " 'Vanuatu' 'Venezuela ' 'Viet Nam' 'Wallis and Futuna Islands' 'Yemen'\n",
      " 'Zambia' 'Zimbabwe']\n"
     ]
    }
   ],
   "source": [
    "unique_countries = energy_df['Country'].unique()\n",
    "print(unique_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help pd.read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "CParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 33, saw 7\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCParserError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-5092db40dcc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgdp_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://api.worldbank.org/v2/en/indicator/NY.GDP.MKTP.CD?downloadformat=csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgdp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdp_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/nigelnicholson/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nigelnicholson/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m _parser_defaults = {\n",
      "\u001b[0;32m/Users/nigelnicholson/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    813\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skip_footer not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nigelnicholson/anaconda/lib/python3.5/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.read (pandas/parser.c:8748)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._read_low_memory (pandas/parser.c:9003)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._read_rows (pandas/parser.c:9731)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._tokenize_rows (pandas/parser.c:9602)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.raise_parser_error (pandas/parser.c:23325)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 33, saw 7\n"
     ]
    }
   ],
   "source": [
    "# Load the GDP data with countries' GDP from 1960 to 2015 as GDP\n",
    "\n",
    "gdp_file = 'http://api.worldbank.org/v2/en/indicator/NY.GDP.MKTP.CD?downloadformat=csv'\n",
    "\n",
    "gdp = pd.read_csv(gdp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "```\"Korea, Rep.\": \"South Korea\", \n",
    "\"Iran, Islamic Rep.\": \"Iran\",\n",
    "\"Hong Kong SAR, China\": \"Hong Kong\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sheet1']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Country</th>\n",
       "      <th>Documents</th>\n",
       "      <th>Citable documents</th>\n",
       "      <th>Citations</th>\n",
       "      <th>Self-citations</th>\n",
       "      <th>Citations per document</th>\n",
       "      <th>H index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>China</td>\n",
       "      <td>127050</td>\n",
       "      <td>126767</td>\n",
       "      <td>597237</td>\n",
       "      <td>411683</td>\n",
       "      <td>4.70</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>United States</td>\n",
       "      <td>96661</td>\n",
       "      <td>94747</td>\n",
       "      <td>792274</td>\n",
       "      <td>265436</td>\n",
       "      <td>8.20</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Japan</td>\n",
       "      <td>30504</td>\n",
       "      <td>30287</td>\n",
       "      <td>223024</td>\n",
       "      <td>61554</td>\n",
       "      <td>7.31</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>20944</td>\n",
       "      <td>20357</td>\n",
       "      <td>206091</td>\n",
       "      <td>37874</td>\n",
       "      <td>9.84</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Russian Federation</td>\n",
       "      <td>18534</td>\n",
       "      <td>18301</td>\n",
       "      <td>34266</td>\n",
       "      <td>12422</td>\n",
       "      <td>1.85</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank             Country  Documents  Citable documents  Citations  \\\n",
       "0     1               China     127050             126767     597237   \n",
       "1     2       United States      96661              94747     792274   \n",
       "2     3               Japan      30504              30287     223024   \n",
       "3     4      United Kingdom      20944              20357     206091   \n",
       "4     5  Russian Federation      18534              18301      34266   \n",
       "\n",
       "   Self-citations  Citations per document  H index  \n",
       "0          411683                    4.70      138  \n",
       "1          265436                    8.20      230  \n",
       "2           61554                    7.31      134  \n",
       "3           37874                    9.84      139  \n",
       "4           12422                    1.85       57  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sciamgo Journal data for Energy Engineering and Power Technology\n",
    "# This ranks countries based on their journal contribution in EE and PT\n",
    "sciamgo_file = 'http://www.scimagojr.com/countryrank.php?category=2102&out=xls'\n",
    "\n",
    "# Load spreadsheet: xl\n",
    "journal_ctb_xl = pd.ExcelFile(sciamgo_file)\n",
    "\n",
    "# Print sheet names\n",
    "print(journal_ctb_xl.sheet_names)\n",
    "\n",
    "# Call this DataFrame **ScimEn**\n",
    "ScimEn = journal_ctb_xl.parse(0)\n",
    "\n",
    "ScimEn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(df.info) \n",
    "print(df.columns)\n",
    "print(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Question 2 is asking about the number of unique rows (data entries) that's lost when merging the three data frames.\n",
    "\n",
    "pd.merge(df_left,df_right,on='commonkey')\n",
    "On the other hand if the dataframes shared a common index we use:\n",
    "\n",
    "pd.merge(df_left,df_right,left_index=True,right_index=True)\n",
    "You can also have one dataframe joined on its index and the other on its column. For example if df_left's index is the same as \"commonkey\" column in df_right we use:\n",
    "\n",
    "pd.merge(df_left,df_right,left_index=True,right_on='commonkey')\n",
    "All the questions from Q3 onwards, are directed specifically at the output of the answer_one function, that's why it was pre-coded in all these questions.\n",
    "\n",
    "Your feedback on the questions phrasing is truly appreciated and will be utilized in improving the this course.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To simplify matters, create a function get_dataframes() that carry out the steps in Q 1 \n",
    "# until just before the merging step, the function would returns the three data frames.\n",
    "def get_dataframes():\n",
    "\n",
    "  #Your code here \n",
    "  return Energy, GDP, ScimEn\n",
    "\n",
    "# you can use the function to in Q1\n",
    "\n",
    "def answer_one():\n",
    "  Energy, GDP, ScimEn = get_dataframes()\n",
    "  # code for merging and slicing steps\n",
    "  return \"YOUR ANSWER HERE\"\n",
    "\n",
    "# and for Q2\n",
    "\n",
    "def answer_two():\n",
    "  Energy, GDP, ScimEn = get_dataframes()\n",
    "  # code for findin the number of records\n",
    "  return \"YOUR ANSWER HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
