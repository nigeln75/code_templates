{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sqlachemy provides a common way to connect to many different types of database:\n",
    "# SQLite, PostgreSQL, MySQL, MS SQL, Oracle and many more\n",
    "# 2 main parts to SQLAchemy: Core (Relational Model focused) AND ORM (User Data Model focused)\n",
    "\n",
    "# Engine: common interface to the database from SQLAlchemy\n",
    "# Connection string: All the details required to find the database (and login, if necessary)\n",
    "from sqlalchemy import create_engine\n",
    "# In the following connection string: 'sqlite:///census_nyc.sqlite':\n",
    "# - sqllitte is called the Driver+Dialect\n",
    "# - census_nyc.sqlite is the Filename\n",
    "engine = create_engine('sqlite:///census_nyc.sqlite')\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Before querying your database, you’ll want to know what is in it: what the tables are, for example:\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///census_nyc.sqlite')\n",
    "print(engine.table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NoSuchTableError",
     "evalue": "census",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchTableError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-80e24dc31316>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMetaData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Instruct Python to autoload the table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mcensus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'census'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoload_with\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m# Use function repr to see column names and types of columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcensus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nigelnicholson/anaconda/envs/py35/lib/python3.5/site-packages/sqlalchemy/sql/schema.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, *args, **kw)\u001b[0m\n\u001b[1;32m    414\u001b[0m                     \u001b[0;34m\"Table '%s' is already defined for this MetaData \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                     \u001b[0;34m\"instance.  Specify 'extend_existing=True' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m                     \u001b[0;34m\"to redefine \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m                     \u001b[0;34m\"options and columns on an \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \"existing Table object.\" % key)\n",
      "\u001b[0;32m/Users/nigelnicholson/anaconda/envs/py35/lib/python3.5/site-packages/sqlalchemy/util/langhelpers.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m   \u001b[0;31m# remove potential circular references\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy3k\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nigelnicholson/anaconda/envs/py35/lib/python3.5/site-packages/sqlalchemy/util/compat.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb, cause)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cause__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcause\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nigelnicholson/anaconda/envs/py35/lib/python3.5/site-packages/sqlalchemy/sql/schema.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, *args, **kw)\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0mmustexist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mustexist'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_table_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkeep_existing\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextend_existing\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 raise exc.InvalidRequestError(\n",
      "\u001b[0;32m/Users/nigelnicholson/anaconda/envs/py35/lib/python3.5/site-packages/sqlalchemy/sql/schema.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, name, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfullname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m         \u001b[0mautoload_with\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoload_with'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[0mautoload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoload'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoload_with\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;31m# this argument is only used with _init_existing()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nigelnicholson/anaconda/envs/py35/lib/python3.5/site-packages/sqlalchemy/sql/schema.py\u001b[0m in \u001b[0;36m_autoload\u001b[0;34m(self, metadata, autoload_with, include_columns, exclude_columns)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'info'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'info'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m'listeners'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0mlisteners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'listeners'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlisteners\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nigelnicholson/anaconda/envs/py35/lib/python3.5/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mrun_callable\u001b[0;34m(self, callable_, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m         \"\"\"\n\u001b[0;32m-> 1972\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextual_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclose_with_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclose_with_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1973\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1974\u001b[0m             \u001b[0mtrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nigelnicholson/anaconda/envs/py35/lib/python3.5/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mrun_callable\u001b[0;34m(self, callable_, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0mUpon\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtransaction\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mcommitted\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mIf\u001b[0m \u001b[0man\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m         \u001b[0mexception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mraised\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtransaction\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mrolled\u001b[0m \u001b[0mback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1477\u001b[0;31m         \u001b[0mbefore\u001b[0m \u001b[0mpropagating\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mnote\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nigelnicholson/anaconda/envs/py35/lib/python3.5/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mreflecttable\u001b[0;34m(self, connection, table, include_columns, exclude_columns)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mcolspecs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0mpasses\u001b[0m \u001b[0mon\u001b[0m \u001b[0mto\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt_type\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \"\"\"\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msqltypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypeobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolspecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nigelnicholson/anaconda/envs/py35/lib/python3.5/site-packages/sqlalchemy/engine/reflection.py\u001b[0m in \u001b[0;36mreflecttable\u001b[0;34m(self, table, include_columns, exclude_columns)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# get table-level arguments that are specifically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0;31m# intended for reflection, e.g. oracle_resolve_synonyms.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;31m# these are unconditionally passed to related Table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;31m# objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchTableError\u001b[0m: census"
     ]
    }
   ],
   "source": [
    "# Reflection\n",
    "# Reflection reads database and builds SQLAlchemy Table objects\n",
    "\n",
    "# SQLAlchemy can be used to automatically load tables from a database using something called reflection. \n",
    "# Reflection is the process of reading the database and building the metadata based on that information. \n",
    "# It's the opposite of creating a Table by hand and is very useful for working with existing databases. \n",
    "# To perform reflection, we need to import the Table object from the SQLAlchemy package. \n",
    "# Then we use the Table object to read our table from the engine and autoload the columns. \n",
    "# Using the Table object in this manner looks like we are using a function.\n",
    "\n",
    "from sqlalchemy import MetaData, Table\n",
    "# Initialise a metadata object\n",
    "metadata = MetaData()\n",
    "# Instruct Python to autoload the table\n",
    "census = Table('census', metadata, autoload=True, autoload_with=engine)\n",
    "# Use function repr to see column names and types of columns\n",
    "print(repr(census))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With our table reflected, we can begin to learn more about the columns and structure of our table. \n",
    "# It is important to get an understanding of our database by examining the column names. \n",
    "# This can be done by using the columns attribute and accessing the keys() method. \n",
    "# For example, census.columns.keys() would return a list of column names on the census table.\n",
    "\n",
    "# Following this, we can use the metadata container to find out more details about the reflected table such as the columns and their types.\n",
    "# Reflect census table from the engine: census\n",
    "census = Table('census', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "# Print columns names\n",
    "print(census.columns.keys())\n",
    "\n",
    "# Print full table metadata\n",
    "print(repr(metadata.tables['census']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select, Insert, Update & Delete data Create & Alter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Basic SQL querying:\n",
    "# - SELECT column_name FROM table_name\n",
    "# - SELECT pop2008 FROM People\n",
    "# - SELECT * FROM People"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting data from a Table: raw SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Basic SQL querying\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///census_nyc.sqlite')\n",
    "connection = engine.connect()\n",
    "# Create an object to hold the SQL query\n",
    "stmt = 'SELECT * FROM people'\n",
    "# Execute the query and assign this to variable results_proxy\n",
    "result_proxy = connection.execute(stmt)\n",
    "# We can then retrieve all of the data from result_proxy with the fetchall method\n",
    "results = result_proxy.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting data from a Table with SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SQLAlchemy to Build Queries\n",
    "# - Provides a Pythonic way to build SQL statements \n",
    "# - Hides differences between backend database types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SQLAlchemy querying\n",
    "\n",
    "# Import select\n",
    "from sqlalchemy import select\n",
    "\n",
    "# Reflect census table via engine: census\n",
    "census = Table('census', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "# Build select statement for census table: stmt\n",
    "stmt = select([census])\n",
    "\n",
    "# Print the emitted statement to see the SQL emitted\n",
    "print(stmt)\n",
    "\n",
    "# Execute the statement and print the results\n",
    "print(connection.execute(stmt).fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SQLAlchemy Select Statement\n",
    "# - Requires a list of one or more Tables or Columns \n",
    "# - Using a table will select all the columns in it\n",
    "stmt = select([census])\n",
    "In [10]: print(stmt)\n",
    "Out[10]: 'SELECT * from CENSUS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ResultProxy: The object returned by the execute() method. It can be used in a variety of ways to get the data returned by the query.\n",
    "# ResultSet: The actual data asked for in the query when using a fetch method such as fetchall() on a ResultProxy.\n",
    "\n",
    "# This separation between the ResultSet and ResultProxy allows us to fetch as much or as little data as we desire\n",
    "\n",
    "# ResultProxy\n",
    "result_proxy = connection.execute(stmt)\n",
    "# ResultSet - contains the data we ask for in the query\n",
    "results = result_proxy.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Handling a ResultSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Handling ResultSets\n",
    "# Get the first row of the results by using an index: first_row\n",
    "first_row = results[0]\n",
    "\n",
    "# Print the first row of the results\n",
    "print(first_row)\n",
    "\n",
    "# Print the first column of the row by using an index\n",
    "print(first_row[0])\n",
    "\n",
    "# Print the state column of the row by using its name\n",
    "print(first_row['state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering and Targeting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Where clauses\n",
    "# - Restrict data returned by a query based on boolean conditions\n",
    "# - Compare a column against a value or another column\n",
    "# - Often used comparisons: '==', '<=', '>=', or '!='\n",
    "\n",
    "stmt = select([census])\n",
    "stmt = stmt.where(census.columns.state == 'California')\n",
    "results = connection.execute(stmt).fetchall()\n",
    "for result in results:\n",
    "    print(result.state, result.age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SQL expressions\n",
    "# Provide more complex conditions than simple operators\n",
    "# Eg. in_() matches a column's value against a list, like() matches a column's value against a partial value, between() matches a column's value between 2 values \n",
    "# Many more in documentation \n",
    "# Available as method on a Column\n",
    "stmt = select([census])\n",
    "stmt = stmt.where(\n",
    "census.columns.state.startswith('New'))\n",
    "for result in connection.execute(stmt):\n",
    "    print(result.state, result.pop2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Conjunctions\n",
    "# - Allow us to have multiple criteria in a where clause Eg.and_(),not_(), or_()\n",
    "from sqlalchemy import or_\n",
    "stmt = select([census])\n",
    "stmt = stmt.where(or_(census.columns.state == 'California',\n",
    "                      census.columns.state == 'New York'\n",
    "                  )\n",
    "        )\n",
    "for result in connection.execute(stmt):\n",
    "    print(result.state, result.sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to a PostgreSQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# When connecting to a PostgreSQL database, many prefer to use the psycopg2 database driver, which you have to install before use. \n",
    "# Psycopg2 is preferred as it supports practically all of PostgreSQL's features efficiently and is the standard dialect for PostgreSQL in SQLAlchemy.\n",
    "# There are three components to the connection string in this exercise: \n",
    "# - the dialect and driver ('postgresql+psycopg2://'),\n",
    "# - followed by the username and password ('student:datacamp'), \n",
    "# - followed by the host and port ('@postgresql.csrrinzqubik.us-east-1.rds.amazonaws.com:5432/'),\n",
    "# - and finally, the database name ('census')\n",
    "\n",
    "# Import create_engine function\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create an engine to the census database\n",
    "engine = create_engine('postgresql+psycopg2://student:datacamp@postgresql.csrrinzqubik.us-east-1.rds.amazonaws.com:5432/census')\n",
    "connection = engine.connect()\n",
    "\n",
    "# Use the 'table_names()' method on the engine to print the table names\n",
    "print(engine.table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import select\n",
    "from sqlalchemy import MetaData, Table\n",
    "\n",
    "# Initialise a metadata object\n",
    "metadata = MetaData()\n",
    "\n",
    "# Reflect census table via engine: census\n",
    "census = Table('census', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "# Create a select query: stmt\n",
    "stmt = select([census])\n",
    "\n",
    "# Add a where clause to filter the results to only those for New York\n",
    "stmt = stmt.where(census.columns.state == 'New York')\n",
    "\n",
    "# Execute the query to retrieve all the data returned: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Loop over the results and print the age, sex, and pop2008\n",
    "for result in results:\n",
    "    print(result.age, result.sex, result.pop2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a query for the census table: stmt\n",
    "stmt = select([census])\n",
    "\n",
    "# Append a where clause to match all the states in_ the list states\n",
    "stmt = stmt.where(census.columns.state.in_(states))\n",
    "\n",
    "# Loop over the ResultProxy and print the state and its population in 2000\n",
    "for result in connection.execute(stmt):\n",
    "    print(result.state, result.pop2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter data selected from a Table - Advanced\n",
    "# SQLAlchemy allows users to use conjunctions such as and_(), or_(), and not_() to build more complex filtering\n",
    "\n",
    "# Import and_\n",
    "from sqlalchemy import and_\n",
    "\n",
    "# Build a query for the census table: stmt\n",
    "stmt = select([census])\n",
    "\n",
    "# Append a where clause to select only non-male records from California using and_\n",
    "stmt = stmt.where(\n",
    "    # The state of California with a non-male sex\n",
    "    and_(census.columns.state == 'California',\n",
    "         census.columns.sex != 'M'\n",
    "         )\n",
    ")\n",
    "\n",
    "# Loop over the ResultProxy printing the age and sex\n",
    "for result in connection.execute(stmt):\n",
    "    print(result.age, result.sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordering query results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Order by Clauses\n",
    "# - Allows us to control the order in which records are returned in the query results\n",
    "# - Available as a method on statements order_by()\n",
    "\n",
    "# Build a query to select the state column: stmt\n",
    "stmt = select([census.columns.state])\n",
    "\n",
    "# Append an order_by state\n",
    "stmt = stmt.order_by(census.columns.state)\n",
    "\n",
    "# Execute the query and store the results: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print the first 10 results\n",
    "print(results[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Order by Descending - wrap the column with desc() in the order_by() clause\n",
    "\n",
    "# Import desc\n",
    "from sqlalchemy import desc\n",
    "\n",
    "# Build a query to select the state column: stmt\n",
    "stmt = select([census.columns.state])\n",
    "\n",
    "# Append order_by descending state: rev_stmt\n",
    "rev_stmt = stmt.order_by(desc(census.columns.state))\n",
    "\n",
    "# Execute the query and store the results: rev_results\n",
    "rev_results = connection.execute(rev_stmt).fetchall()\n",
    "\n",
    "# Print the first 10 rev_results\n",
    "print(rev_results[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Order by Multiple\n",
    "# - Just separate multiple columns with a comma Orders completely by the first column\n",
    "# - Then if there are duplicates in the first column,   orders by the second column\n",
    "# - repeat until all columns are ordered\n",
    "\n",
    "# Build a query to select state and age: stmt\n",
    "stmt = select([census.columns.state, census.columns.age])\n",
    "\n",
    "# Append order by to ascend by state and descend by age\n",
    "stmt = stmt.order_by(census.columns.state, desc(census.columns.age))\n",
    "\n",
    "# Execute the statement and store all the records: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print the first 20 results\n",
    "print(results[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Functions to aggregate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# E.g. Count, Sum\n",
    "# from sqlalchemy import func\n",
    "# More efficient than processing in Python\n",
    "\n",
    "from sqlalchemy import func\n",
    "stmt = select([func.sum(census.columns.pop2008)])\n",
    "results = connection.execute(stmt).scalar()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a query to count the distinct states values: stmt\n",
    "stmt = select([func.count(census.columns.state.distinct())])\n",
    "\n",
    "# Execute the query and store the scalar result: distinct_state_count\n",
    "# The ResultProxy also has a method called scalar() for getting just the value of a query that returns only one row and column\n",
    "distinct_state_count = connection.execute(stmt).scalar()\n",
    "\n",
    "# Print the distinct_state_count\n",
    "print(distinct_state_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import func\n",
    "from sqlalchemy.sql import func\n",
    "\n",
    "# Build a query to select the state and count of ages by state: stmt\n",
    "stmt = select([census.columns.state, func.count(census.columns.age)])\n",
    "\n",
    "# Append group by state\n",
    "stmt = stmt.group_by(census.columns.state)\n",
    "\n",
    "# Execute the statement and store all the records: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print results\n",
    "print(results)\n",
    "\n",
    "# Print the keys/column names of the results returned\n",
    "print(results[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example of a groupby\n",
    "stmt = select([census.columns.sex, func.sum(census.columns.pop2008)])\n",
    "stmt = stmt.group_by(census.columns.sex)\n",
    "results = connection.execute(stmt).fetchall()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Group by supports multiple columns to group by with a pattern similar to order_by()\n",
    "# Requires all selected columns to be grouped or aggregated by a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stmt = select([census.columns.sex, census.columns.age, func.sum(census.columns.pop2008)])\n",
    "stmt = stmt.group_by(census.columns.sex, census.columns.age)\n",
    "results = connection.execute(stmt).fetchall()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Handling ResultSets from Functions\n",
    "# SQLAlchemy auto generates “column names” for functions in the ResultSet\n",
    "# The column names are often func_# such as count_1\n",
    "# Replace them with the label() method\n",
    "\n",
    "# Import func\n",
    "from sqlalchemy.sql import func\n",
    "\n",
    "# Build an expression to calculate the sum of pop2008 labeled as population\n",
    "pop2008_sum = func.sum(census.columns.pop2008).label('population')\n",
    "\n",
    "# Build a query to select the state and sum of pop2008 as population grouped by state: stmt\n",
    "stmt = select([census.columns.state, pop2008_sum])\n",
    "\n",
    "# Append group by state\n",
    "stmt = stmt.group_by(census.columns.state)\n",
    "\n",
    "# Execute the statement and store all the records: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print results\n",
    "print(results)\n",
    "\n",
    "# Print the keys/column names of the results returned\n",
    "print(results[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can feed a ResultProxy directly into a pandas DataFrame\n",
    "# import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from the results: df\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Set column names\n",
    "df.columns = results[0].keys()\n",
    "\n",
    "# Print the Dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Pyplot as plt from matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a DataFrame from the results: df\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Set Column names\n",
    "df.columns = results[0].keys()\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Plot the DataFrame\n",
    "df.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing more complex SQL queries using SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculating differences\n",
    "stmt = select([census.columns.age,\n",
    "   ...:     (census.columns.pop2008-\n",
    "   ...:     census.columns.pop2000).label('pop_change')\n",
    "   ...: ])\n",
    "In [2]: stmt = stmt.group_by(census.columns.age)\n",
    "In [3]: stmt = stmt.order_by(desc('pop_change'))\n",
    "In [4]: stmt = stmt.limit(5)\n",
    "In [5]: results = connection.execute(stmt).fetchall()\n",
    "In [6]: print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Case Statement\n",
    "Used to treat data differently based on a condition\n",
    "Accepts a list of conditions to match and a column   to return if the condition matches\n",
    "The list of conditions ends with an else clause to  determine what to do when a record doesn’t match any prior conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cast Statement\n",
    "Converts data to another type Useful for converting\n",
    "integers to floats for division\n",
    "strings to dates and times\n",
    "Accepts a column or expression and the target Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import case, cast, Float\n",
    "stmt = select([(func.sum(case([(census.columns.state == 'New York',census.columns.pop2008)], else_=0)) /\n",
    "cast(func.sum(census.columns.pop2008), Float) * 100).label('ny_percent')])\n",
    "results = connection.execute(stmt).fetchall()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to a MySQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# When connecting to a MySQL database, many prefer to use the pymysql database driver, which you have to install prior to use. \n",
    "# This connection string is going to start with mysql+pymysql://, indicating which dialect and driver we are using to establish the connection. \n",
    "# The dialect block is followed by the username:password combo. \n",
    "# Next, we specify the host and port with the following @host:port/. \n",
    "# Finally, we wrap up the connection string with the database_name. \n",
    "# Now you'll practice connecting to a MySQL database: it will be the same census database that you have already been working with. \n",
    "# One of the great things about SQLAlchemy is that, after connecting, it abstracts over the type of database it has connected to and you can write the same SQLAlchemy code, regardless.\n",
    "\n",
    "# Import create_engine function\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create an engine to the census database\n",
    "engine = create_engine('mysql+pymysql://student:datacamp@courses.csrrinzqubik.us-east-1.rds.amazonaws.com:3306/census')\n",
    "\n",
    "# Use the `table_names()` method on the engine to print the table names\n",
    "print(engine.table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Often, we need to perform math type operations as part of the query, such as the population change from 2000 to 2008. \n",
    "# The operators work the same way for numbers in SQLAlchemy as they do in Python for math operations. \n",
    "# We can perform addition +, subtraction -, multiplication *, division /, and modulus % via operators. \n",
    "# Note: these operators behave differently when used with non-numeric column types. \n",
    "# Let's find the top 5 states by population growth between 2000 and 2008.\n",
    "\n",
    "from sqlalchemy import desc\n",
    "\n",
    "# Build query to return state names by population difference from 2008 to 2000: stmt\n",
    "stmt = select([census.columns.state, (census.columns.pop2008-census.columns.pop2000).label('pop_change')])\n",
    "\n",
    "# Append group by for the state: stmt\n",
    "stmt = stmt.group_by(census.columns.state)\n",
    "\n",
    "# Append order by for pop_change descendingly: stmt\n",
    "stmt = stmt.order_by(desc('pop_change'))\n",
    "\n",
    "# Return only 5 results: stmt\n",
    "stmt = stmt.limit(5)\n",
    "\n",
    "# Use connection to execute the statement and fetch all results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print the state and population change for each record\n",
    "for result in results:\n",
    "    print('{}-{}'.format(result.state, result.pop_change))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Case and Cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# It's possible to combine functions and operators in a single select statement as well. \n",
    "# These combinations can be exceptionally handy when we want to calculate percentages or averages\n",
    "# We can also use the case() statement to operate on data that meets specific criteria while not affecting the query as a whole\n",
    "# The case() statement accepts a list of conditions to match and the column to return if the condition matches, followed by an else if none of the conditions match\n",
    "# We can wrap this entire expression in any function or math operation we like\n",
    "# Often when performing integer division, we want to get a float back\n",
    "# While some databases will do this automatically, you can use the cast statement to convert an expression to a particular type\n",
    "\n",
    "# import case, cast and Float from sqlalchemy\n",
    "from sqlalchemy import case, cast, Float\n",
    "\n",
    "# Build an expression to calculate female population in 2000\n",
    "female_pop2000 = func.sum(\n",
    "    case([\n",
    "        (census.columns.sex == 'F', census.columns.pop2000)\n",
    "    ], else_=0))\n",
    "\n",
    "# Cast an expression to calculate total population in 2000 to Float\n",
    "total_pop2000 = cast(func.sum(census.columns.pop2000), Float)\n",
    "\n",
    "# Build a query to calculate the percentage of females in 2000: stmt\n",
    "stmt = select([female_pop2000 / total_pop2000 * 100])\n",
    "\n",
    "# Execute the query and store the scalar result: percent_female\n",
    "percent_female = connection.execute(stmt).scalar()\n",
    "\n",
    "# Print the percentage\n",
    "print(percent_female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Allows us to avoid duplicating data\n",
    "# Makes it easy to change data in only one place\n",
    "# Good way of storing data we don't need to use very often"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Automatic Joins with an Established Relationship\n",
    "# If we have two tables that already have an established relationship, we can automatically use that relationship by just adding the columns we want from each table to the select statement\n",
    "\n",
    "# Build a statement to join census and state_fact tables: stmt\n",
    "stmt = select([census.columns.pop2000, state_fact.columns.abbreviation])\n",
    "\n",
    "# Execute the statement and get the first result: result\n",
    "result = connection.execute(stmt).first()\n",
    "\n",
    "# Loop over the keys in the result object and print the key and value\n",
    "for key in result.keys():\n",
    "    print(key, getattr(result, key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If we aren't selecting columns from both tables or the two tables don't have a defined relationship, we can still use the join() method on a table to join it with another table and get extra data related to our query. \n",
    "# The join() takes the table object we want to join in as the first argument and a condition that indicates how the tables are related to the second argument. \n",
    "# Finally, we use the select_from() method on the select statement to wrap the join clause. \n",
    "\n",
    "# Build a statement to select the census and state_fact tables: stmt\n",
    "stmt = select([census, state_fact])\n",
    "\n",
    "# Add a select_from clause that wraps a join for the census and state_fact\n",
    "# tables where the census state column and state_fact name column match\n",
    "stmt = stmt.select_from(\n",
    "    census.join(state_fact, census.columns.state == state_fact.columns.name))\n",
    "\n",
    "# Execute the statement and get the first result: result\n",
    "result = connection.execute(stmt).first()\n",
    "\n",
    "# Loop over the keys in the result object and print the key and value\n",
    "for key in result.keys():\n",
    "    print(key, getattr(result, key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a statement to select the state, sum of 2008 population and census\n",
    "# division name: stmt\n",
    "stmt = select([\n",
    "    census.columns.state,\n",
    "    func.sum(census.columns.pop2008),\n",
    "    state_fact.columns.census_division_name\n",
    "])\n",
    "\n",
    "# Append select_from to join the census and state_fact tables by the census state and state_fact name columns\n",
    "stmt = stmt.select_from(\n",
    "    census.join(state_fact, census.columns.state == state_fact.columns.name)\n",
    ")\n",
    "\n",
    "# Append a group by for the state_fact name column\n",
    "stmt = stmt.group_by(state_fact.columns.name)\n",
    "\n",
    "# Execute the statement and get the results: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Loop over the the results object and print each record.\n",
    "for record in results:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical data - using alias to handle same table joined queries\n",
    "For example, a list of managers and their employees from an employee table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Often, we will have tables that contain hierarchical data, such as employees and managers who are also employees. \n",
    "# For this reason, we may wish to join a table to itself on different columns. \n",
    "# The alias() method, which creates a copy of a table, helps us accomplish this task.\n",
    "# Because it's the same table, we only need a where clause to specify the join condition. \n",
    "# Let's use the alias() method to build a query to join the employees table against itself to determine to whom everyone reports.\n",
    "\n",
    "# Make an alias of the employees table: managers\n",
    "managers = employees.alias()\n",
    "\n",
    "# Build a query to select manager's and their employees names: stmt\n",
    "stmt = select(\n",
    "    [managers.columns.name.label('manager'),\n",
    "     employees.columns.name.label('employee')]\n",
    ")\n",
    "\n",
    "# Append where to match manager ids with employees managers: stmt\n",
    "stmt = stmt.where(managers.columns.id == employees.columns.mgr)\n",
    "\n",
    "# Append order by managers name: stmt\n",
    "stmt = stmt.order_by(managers.columns.name)\n",
    "\n",
    "# Execute statement: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print records\n",
    "for record in results:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Leveraging Functions and Group_bys with Hierarchical Data\n",
    "# It's also common to want to roll up data which is in a hierarchical table\n",
    "# Rolling up data requires making sure we are careful which alias we use to perform the group_bys and which table we use for the function. \n",
    "# Let's get a count of employees for each manager\n",
    "\n",
    "# Make an alias of the employees table: managers\n",
    "managers = employees.alias()\n",
    "\n",
    "# Build a query to select managers and counts of their employees: stmt\n",
    "stmt = select([managers.columns.name, func.count(employees.columns.id)])\n",
    "\n",
    "# Append a where clause that ensures the manager id and employee mgr are equal\n",
    "stmt = stmt.where(managers.columns.id == employees.columns.mgr)\n",
    "\n",
    "# Group by Managers Name\n",
    "stmt = stmt.group_by(managers.columns.name)\n",
    "\n",
    "# Execute statement: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# print manager\n",
    "for record in results:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling large results can be problematic because of limited memory and disk space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Occasionally, we have the need to work on a large ResultProxy, and don't have the memory to load all the results at once. \n",
    "# To work around that issue, we can get blocks of rows from the ResultProxy with the fetchmany() method. \n",
    "# With fetchmany(), give it an argument of the number of records we want. \n",
    "# When we reach an empty list, there are no more rows left to fetch, and we have processed all the results of the query. \n",
    "# Then you need to use the close() method to close out the connection to the database.\n",
    "\n",
    "# We have already built a query with a ResultProxy called results_proxy.\n",
    "\n",
    "# Start a while loop checking for more results\n",
    "while more_results:\n",
    "    # Fetch the first 50 results from the ResultProxy: partial_results\n",
    "    partial_results = results_proxy.fetchmany(50)\n",
    "\n",
    "    # if empty list, set more_results to False\n",
    "    if partial_results == []:\n",
    "        more_results = False\n",
    "\n",
    "    # Loop over the fetched records and increment the count for the state: state_count\n",
    "    for row in partial_results:\n",
    "        if row.state in state_count:\n",
    "            state_count[row.state]+=1\n",
    "        else:\n",
    "            state_count[row.state]=1\n",
    "\n",
    "# Close the ResultProxy, and thus the connection\n",
    "results_proxy.close()\n",
    "\n",
    "# Print the count by state\n",
    "print(state_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating databases and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating Databases\n",
    "# Varies by the database type\n",
    "# Databases like PostgreSQL and MySQL have  command line tools to initialize the database\n",
    "# With SQLite, the create_engine() statement will create the database and file if they do not already exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating Tables\n",
    "# Still uses the Table object like we did for reflection\n",
    "# Replaces the autoload keyword arguments with Column objects\n",
    "# Creates the tables in the actual database by using   the create_all() method on the MetaData instance\n",
    "# You need to use other tools to handle database table updates, such as Alembic or raw SQL\n",
    "\n",
    "# Previously, we used the Table object to reflect a table from an existing database\n",
    "# To create a table we still use the Table object but we replace the autoload keyword arguments with Column objects\n",
    "# The Column object takes a name, a SQLAlchemy type with an optional format, and optional keyword arguments for different constraints\n",
    "# With the table defined, we're now ready to create the table in the database by using the create_all method on metadata and supplying the engine as the only parameter\n",
    "\n",
    "# Import Table, Column, String, Integer, Float, Boolean from sqlalchemy\n",
    "from sqlalchemy import Table, Column, String, Integer, Float, Boolean, MetaData\n",
    "\n",
    "# Initialise a metadata object\n",
    "metadata = MetaData()\n",
    "\n",
    "# Define a new table with a name, count, amount, and valid column: data\n",
    "data = Table('data', metadata,\n",
    "             Column('name', String(255)),\n",
    "             Column('count', Integer()),\n",
    "             Column('amount', Float()),\n",
    "             Column('valid', Boolean())\n",
    ")\n",
    "\n",
    "# Use the metadata to create the table\n",
    "metadata.create_all(engine)\n",
    "\n",
    "# Print table repr\n",
    "print(repr(data))\n",
    "\n",
    "# Often, you need to make sure that a column is unique, nullable, a positive value, or related to a column in another table\n",
    "# These are called constraints\n",
    "# Many constraints are keywords on the column itself; however, they can also be passed directly to the Table object as well\n",
    "# In addition to constraints, you can also set a default value for the column if no data is passed to it via the default keyword on the column\n",
    "# There is also an onupdate keyword for setting the column value when the row is updated\n",
    "# This is extremely useful for keeping datetime stamps for auditing purposes\n",
    "\n",
    "# Creating Tables - Additional Column Options:\n",
    "# - unique forces all values for the data in a column to be unique\n",
    "# - nullable determines if a column can be empty in a   row\n",
    "# - default sets a default value if one isn’t supplied.\n",
    "\n",
    "# Import Table, Column, String, Integer, Float, Boolean from sqlalchemy\n",
    "from sqlalchemy import Table, Column, String, Integer, Float, Boolean\n",
    "\n",
    "# Define a new table with a name, count, amount, and valid column: data\n",
    "data = Table('data', metadata,\n",
    "             Column('name', String(255), unique=True),\n",
    "             Column('count', Integer(), default=1),\n",
    "             Column('amount', Float()),\n",
    "             Column('valid', Boolean(), default=False)\n",
    ")\n",
    "\n",
    "# Use the metadata to create the table\n",
    "metadata.create_all(engine)\n",
    "\n",
    "# Print the table details\n",
    "print(repr(metadata.tables['data']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserting data into the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserting a single row with an insert() statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Uses an insert statement where you specify the table as an argument\n",
    "# You then supply the data you wish to insert into the value via the .values() method as keyword arguments.\n",
    "\n",
    "# Import insert and select from sqlalchemy\n",
    "from sqlalchemy import insert, select\n",
    "\n",
    "# Build an insert statement to insert a record into the data table: stmt\n",
    "stmt = insert(data).values(name='Anna', count=1, amount=1000.00, valid=True)\n",
    "\n",
    "# Execute the statement via the connection: results\n",
    "results = connection.execute(stmt)\n",
    "\n",
    "# Print result rowcount\n",
    "print(results.rowcount)\n",
    "\n",
    "# Build a select statement to validate the insert\n",
    "stmt = select([data]).where(data.columns.name == \"Anna\")\n",
    "\n",
    "# Print the result of executing the query.\n",
    "print(connection.execute(stmt).first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserting Multiple Records at Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Often we want to insert more than just one record. \n",
    "# In that case, we'll want to build a list of dictionaries that represents our data we want to insert and pair that with an insert statement in the execute method of the connection\n",
    "# To do so we first build an insert statement for the table data without the values using stmt=insert(data)\n",
    "# We then pass the list of data dictionaries as the second argument to the execute method (and, as before, stmt as the first argument)\n",
    "\n",
    "# Build a list of dictionaries: values_list\n",
    "values_list = [\n",
    "    {'name': 'Anna', 'count': 1, 'amount': 1000.00, 'valid': True},\n",
    "    {'name': 'Taylor', 'count': 1, 'amount': 750.00, 'valid': False}\n",
    "]\n",
    "\n",
    "# Build an insert statement for the data table: stmt\n",
    "stmt = insert(data)\n",
    "\n",
    "# Execute stmt with the values_list: results\n",
    "results = connection.execute(stmt, values_list)\n",
    "\n",
    "# Print rowcount\n",
    "print(results.rowcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a CSV into a Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can load the contents of a CSV file into a table by using the multiple insert from the prior exercise and the python csv module\n",
    "# Here we are using a csv_reader that has already been setup for you\n",
    "# The csv_reader returns a list that represents in line from the CSV file\n",
    "# We can loop over the csv_reader to handle the results one at a time\n",
    "# The enumerate function can be used with a csv_reader to return the line number and the data as a tuple starting from line 0.\n",
    "\n",
    "# Create a insert statement for census: stmt\n",
    "stmt = insert(census)\n",
    "\n",
    "# Create an empty list and zeroed row count: values_list, total_rowcount\n",
    "values_list = []\n",
    "total_rowcount = 0\n",
    "\n",
    "# Enumerate the rows of csv_reader\n",
    "for idx, row in enumerate(csv_reader):\n",
    "    #create data and append to values_list\n",
    "    data = {'state': row[0], 'sex': row[1], 'age': row[2], 'pop2000': row[3],\n",
    "            'pop2008': row[4]}\n",
    "    values_list.append(data)\n",
    "\n",
    "    # Check to see if divisible by 51\n",
    "    if idx % 51 == 0:\n",
    "        results = connection.execute(stmt, values_list)\n",
    "        total_rowcount += results.rowcount\n",
    "        values_list = []\n",
    "\n",
    "# Print total rowcount\n",
    "print(total_rowcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating data in a database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating a single record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The update statement is very similar to an insert statement\n",
    "# The difference that it also typically uses a where clause to help us determine what data to update\n",
    "# We'll be using the FIPS state code using here, which is appropriated by the U.S. government to identify U.S. states and certain other associated areas\n",
    "# Recall that you can update all wages in the employees table as follows:\n",
    "# - stmt = update(employees).values(wage=100.00)\n",
    "# For your convenience, the names of the tables and columns of interest in this exercise are: state_fact (Table), name (Column), and fips_state (Column)\n",
    "\n",
    "# Build a select statement: select_stmt\n",
    "select_stmt = select([state_fact]).where(state_fact.columns.name == 'New York')\n",
    "\n",
    "# Print the results of executing the select_stmt\n",
    "print(connection.execute(select_stmt).fetchall())\n",
    "\n",
    "# Build a statement to update the fips_state to 36: stmt\n",
    "stmt = update(state_fact).values(fips_state=36)\n",
    "\n",
    "# Append a where clause to limit it to records for New York state\n",
    "stmt = stmt.where(state_fact.columns.name == 'New York')\n",
    "\n",
    "# Execute the statement: results\n",
    "results = connection.execute(stmt)\n",
    "\n",
    "# Print rowcount\n",
    "print(results.rowcount)\n",
    "\n",
    "# Execute the select_stmt again to view the changes\n",
    "print(connection.execute(select_stmt).fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating multiple records in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# By using a where clause that would select more records, we can update Multiple records at once\n",
    "# Build a statement to update the notes to 'The Wild West': stmt\n",
    "stmt = update(state_fact).values(notes='The Wild West')\n",
    "\n",
    "# Append a where clause to match the West census region records\n",
    "stmt = stmt.where(state_fact.columns.census_region_name == 'West')\n",
    "\n",
    "# Execute the statement: results\n",
    "results = connection.execute(stmt)\n",
    "\n",
    "# Print rowcount\n",
    "print(results.rowcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing a 'correlated update' using a select statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can also update records with data from a select statement\n",
    "# This is called a correlated update\n",
    "# It works by defining a select statement that returns the value we want to update the record with and assigning that as the value in an update statement\n",
    "# We'll be using a flat_census in this exercise as the target of our correlated update\n",
    "# The flat_census table is a summarized copy of our census table.\n",
    "\n",
    "# Build a statement to select name from state_fact: stmt\n",
    "fips_stmt = select([state_fact.columns.name])\n",
    "\n",
    "# Append a where clause to Match the fips_state to flat_census fips_code\n",
    "fips_stmt = fips_stmt.where(\n",
    "    state_fact.columns.fips_state == flat_census.columns.fips_code)\n",
    "\n",
    "# Build an update statement to set the name to fips_stmt: update_stmt\n",
    "update_stmt = update(flat_census).values(state_name=fips_stmt)\n",
    "\n",
    "# Execute update_stmt: results\n",
    "results = connection.execute(update_stmt)\n",
    "\n",
    "# Print rowcount\n",
    "print(results.rowcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing data from a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Often, we need to empty a table of all of its records so we can reload the data\n",
    "# We do this with a delete statement with just the table as an argument\n",
    "\n",
    "# Deleting Data from a Table\n",
    "# Done with the delete() statement\n",
    "# delete() takes the table we are loading data into as the argument\n",
    "# A where() clause is used to choose which rows to delete\n",
    "# Hard to undo so BE CAREFUL!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import delete, select\n",
    "from sqlalchemy import delete, select\n",
    "\n",
    "# Build a statement to empty the census table: stmt\n",
    "stmt = delete(census)\n",
    "\n",
    "# Execute the statement: results\n",
    "results = connection.execute(stmt)\n",
    "\n",
    "# Print affected rowcount\n",
    "print(results.rowcount)\n",
    "\n",
    "# Build a statement to select all records from the census table\n",
    "stmt = select([census])\n",
    "\n",
    "# Print the results of executing the statement to verify there are no rows\n",
    "print(connection.execute(stmt).fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deleting specific rows\n",
    "# By using a where() clause we can target the delete statement to remove only certain records\n",
    "\n",
    "# Build a statement to count records using the sex column for Men (M) age 36: stmt\n",
    "stmt = select([func.count(census.columns.sex)]).where(\n",
    "    and_(census.columns.sex == 'M',\n",
    "         census.columns.age == 36)\n",
    ")\n",
    "\n",
    "# Execute the select statement and use the scalar() fetch method to save the record count\n",
    "to_delete = connection.execute(stmt).scalar()\n",
    "\n",
    "# Build a statement to delete records from the census table: stmt_del\n",
    "stmt_del = delete(census)\n",
    "\n",
    "# Append a where clause to target man age 36\n",
    "stmt_del = stmt_del.where(\n",
    "    and_(census.columns.sex == 'M',\n",
    "         census.columns.age == 36)\n",
    ")\n",
    "\n",
    "# Execute the statement: results\n",
    "results = connection.execute(stmt_del)\n",
    "\n",
    "# Print affected rowcount and to_delete record count, make sure they match\n",
    "print(results.rowcount, to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropping a Table Completely\n",
    "# Uses the drop method on the table\n",
    "# Accepts the engine as an argument so it knows where to remove the table from\n",
    "# Won’t remove it from metadata until the python process is restarted\n",
    "\n",
    "# We can delete a table from the database by using the drop() method found on the table object\n",
    "# We can also drop all the tables by using a drop_all() method on the metadata object\n",
    "# Finally, we can check to see if a table exists with the exists() method of that table\n",
    "# All of these methods take the engine engine as the argument (it has already been created)\n",
    "# Supplying the engine allows it to know which database to target\n",
    "# (NOTE: these operations affect the database, and will not remove the python references to the objects)\n",
    "\n",
    "# Drop the state_fact table\n",
    "state_fact.drop(engine)\n",
    "\n",
    "# Check to see if state_fact exists\n",
    "print(state_fact.exists(engine))\n",
    "\n",
    "# Dropping all the tables - uses the drop_all() method on MetaData\n",
    "# Drop all tables\n",
    "metadata.drop_all(engine)\n",
    "\n",
    "# Check to see if census exists\n",
    "print(census.exists(engine))\n",
    "\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Census case study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the Engine and MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import create_engine, MetaData\n",
    "from sqlalchemy import create_engine, MetaData\n",
    "\n",
    "# Define an engine to connect to chapter5.sqlite: engine\n",
    "engine = create_engine('sqlite:///chapter5.sqlite')\n",
    "\n",
    "# Initialize MetaData: metadata\n",
    "metadata = MetaData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Table to the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Having setup the engine and initialized the metadata, you will now define the census table object and then create it in the database using using the metadata and engine. \n",
    "# To create it in the database, you will have to use the .create_all() method on the metadata with engine as the argument\n",
    "\n",
    "# Import Table, Column, String, and Integer\n",
    "from sqlalchemy import Table, Column, String, Integer\n",
    "\n",
    "# Build a census table: census\n",
    "census = Table('census', metadata,\n",
    "               Column('state', String(30)),\n",
    "               Column('sex', String(1)),\n",
    "               Column('age', Integer()),\n",
    "               Column('pop2000', Integer()),\n",
    "               Column('pop2008', Integer()))\n",
    "\n",
    "# Create the table in the database\n",
    "metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Data from the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Leverage the Python CSV module from the standard library and load the data into a list of dictionaries\n",
    "# Create an empty list: values_list\n",
    "values_list = []\n",
    "\n",
    "# Iterate over the rows\n",
    "for row in csv_reader:\n",
    "    # Create a dictionary with the values\n",
    "    data = {'state': row[0], 'sex': row[1], 'age': row[2], 'pop2000': row[3],\n",
    "            'pop2008': row[4]}\n",
    "    # Append the dictionary to the values list\n",
    "    values_list.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data from a list into the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using the multiple insert pattern, in this exercise, you will load the data from values_list into the table.\n",
    "# Import insert\n",
    "from sqlalchemy import insert\n",
    "\n",
    "# Build insert statement: stmt\n",
    "stmt = insert(census)\n",
    "\n",
    "# Use values_list to insert data: results\n",
    "results = connection.execute(stmt, values_list)\n",
    "\n",
    "# Print rowcount\n",
    "print(results.rowcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Query to Determine the Average Age by Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import select\n",
    "from sqlalchemy import select\n",
    "\n",
    "# Calculate weighted average age: stmt\n",
    "stmt = select([census.columns.sex,\n",
    "               (func.sum(census.columns.pop2008 * census.columns.age) /\n",
    "                func.sum(census.columns.pop2008)).label('average_age')\n",
    "               ])\n",
    "\n",
    "# Group by sex\n",
    "stmt = stmt.group_by(census.columns.sex)\n",
    "\n",
    "# Execute the query and store the results: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print the average age by sex\n",
    "for result in results:\n",
    "    print(result.sex, result.average_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Query to Determine the Percentage of Population by Gender and State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import case, cast and Float from sqlalchemy\n",
    "from sqlalchemy import case, cast, Float\n",
    "\n",
    "# Build a query to calculate the percentage of females in 2000: stmt\n",
    "stmt = select([census.columns.state,\n",
    "    (func.sum(\n",
    "        case([\n",
    "            (census.columns.sex == 'F', census.columns.pop2000)\n",
    "        ], else_=0)) /\n",
    "     cast(func.sum(census.columns.pop2000), Float) * 100).label('percent_female')\n",
    "])\n",
    "\n",
    "# Group By state\n",
    "stmt = stmt.group_by(census.columns.state)\n",
    "\n",
    "# Execute the query and store the results: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print the percentage\n",
    "for result in results:\n",
    "    print(result.state, result.percent_female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Query to Determine the Difference by State from the 2000 and 2008 Censuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build query to return state name and population difference from 2008 to 2000\n",
    "stmt = select([census.columns.state,\n",
    "     (census.columns.pop2008-census.columns.pop2000).label('pop_change')\n",
    "])\n",
    "\n",
    "# Group by State\n",
    "stmt = stmt.group_by(census.columns.state)\n",
    "\n",
    "# Order by Population Change\n",
    "stmt = stmt.order_by(desc('pop_change'))\n",
    "\n",
    "# Limit to top 10\n",
    "stmt = stmt.limit(10)\n",
    "\n",
    "# Use connection to execute the statement and fetch all results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print the state and population change for each record\n",
    "for result in results:\n",
    "    print('{}-{}'.format(result.state, result.pop_change))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
